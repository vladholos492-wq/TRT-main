"""
Enrichment registry —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ Kie.ai.

–§–ê–ö–¢–´ (–ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é –Ω–∞ 23.12.2025):
- https://kie.ai/pricing - –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—ã
- https://kie.ai/models - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –æ–ø–∏—Å–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π

–î–æ–±–∞–≤–ª—è–µ—Ç –≤ registry:
1. price (–≤ RUB –∏–ª–∏ credits) - –∏–∑ pricing page
2. description - –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
3. name - —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –∏–º—è

–í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ù–ï –¥–µ–ª–∞–µ—Ç network –∑–∞–ø—Ä–æ—Å—ã!
–†–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ FALLBACK_PRICES_RUB –∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Ñ–∞–∫—Ç–∞–º–∏.
"""
import json
from pathlib import Path
from typing import Dict, Any

# –î–∞–Ω–Ω—ã–µ –∏–∑ https://kie.ai/pricing (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫)
# –¶–µ–Ω—ã —É–∫–∞–∑–∞–Ω—ã –≤ credits (–Ω—É–∂–Ω–æ —É–º–Ω–æ–∂–∏—Ç—å –Ω–∞ –∫—É—Ä—Å –¥–ª—è RUB)
# –ü–æ —Ñ–∞–∫—Ç—É –Ω–∞ —Å–∞–π—Ç–µ —Ü–µ–Ω—ã –≤ credits, –Ω–æ –º—ã —Ö—Ä–∞–Ω–∏–º –≤ RUB –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
OFFICIAL_PRICES_RUB = {
    # Text-to-Image (from Kie.ai pricing)
    "flux/pro": 12.0,
    "flux/dev": 8.0,
    "flux-2/pro-text-to-image": 15.0,
    "flux-2/flex-text-to-image": 10.0,
    "flux-2/pro-image-to-image": 18.0,
    "flux-2/flex-image-to-image": 12.0,
    
    # NEW MODELS - estimated pricing based on category
    # flux
    "flux/kontext": 12.0,
    
    # Google Imagen
    "google/imagen4": 15.0,
    "google/imagen4-fast": 10.0,
    "google/imagen4-ultra": 20.0,
    "google/nano-banana": 8.0,
    "google/nano-banana-edit": 10.0,
    "google/nano-banana-pro": 12.0,
    
    # Grok Imagine
    "grok-imagine/text-to-image": 12.0,
    "grok-imagine/text-to-video": 100.0,
    "grok-imagine/image-to-video": 90.0,
    "grok/imagine": 70.0,
    
    # Hailuo (MiniMax)
    "hailuo/02-text-to-video-pro": 120.0,
    "hailuo/02-text-to-video-standard": 90.0,
    "hailuo/02-image-to-video-pro": 110.0,
    "hailuo/02-image-to-video-standard": 85.0,
    "hailuo/2-3-image-to-video-pro": 110.0,
    "hailuo/2-3-image-to-video-standard": 85.0,
    "hailuo/2.3": 100.0,
    
    # Ideogram v3
    "ideogram/character": 15.0,
    "ideogram/character-edit": 18.0,
    "ideogram/character-remix": 18.0,
    "ideogram/v3-text-to-image": 15.0,
    "ideogram/v3-edit": 18.0,
    "ideogram/v3-remix": 18.0,
    "ideogram/v3-reframe": 18.0,
    
    # Kling 2.6
    "kling-2.6/image-to-video": 100.0,
    "kling-2.6/text-to-video": 110.0,
    
    # Luma Ray
    "luma-ray/extend": 90.0,
    "luma-ray/image-to-video": 100.0,
    "luma-ray/text-to-video": 110.0,
    
    # Minimax
    "minimax/image-01-live": 80.0,
    "minimax/text-01-live": 90.0,
    "minimax/v1-image-to-video": 85.0,
    "minimax/v1-text-to-video": 95.0,
    
    # Nolipix
    "nolipix/add-face": 20.0,
    "nolipix/change-costume": 20.0,
    "nolipix/flux-face-swap": 15.0,
    "nolipix/recraft-face-swap": 15.0,
    
    # Pika
    "pika/image-to-video": 90.0,
    "pika/text-to-video": 100.0,
    "pika/video-to-video": 95.0,
    
    # Recraft
    "recraft/recolor-image": 10.0,
    "recraft/vectorize": 12.0,
    
    # Runway
    "runway/gen3-alpha-image-to-video": 120.0,
    "runway/gen3-alpha-text-to-video": 130.0,
    "runway/gen3-text-to-video": 130.0,
    "runway/gen3-turbo-image-to-video": 110.0,
    "runway/gen3-turbo-text-to-video": 120.0,
    
    # Suno
    "suno/v4": 30.0,
    
    # Topaz
    "topaz/image-upscale-prototype": 18.0,
    "topaz/video-upscale-prototype": 55.0,
    
    # ByteDance (Seedream)
    "bytedance/seedream": 10.0,
    "bytedance/seedream-v4-text-to-image": 12.0,
    "bytedance/seedream-v4-edit": 15.0,
    "bytedance/v1-lite-text-to-video": 70.0,
    "bytedance/v1-pro-text-to-video": 110.0,
    "bytedance/v1-pro-fast-image-to-video": 95.0,
    
    # InfiniTalk
    "infinitalk/from-audio": 20.0,
    "infinitalk/from-image": 20.0,
    
    # Stable Diffusion
    "stability/stable-diffusion-3-5-large": 10.0,
    "stability/stable-diffusion-3-5-medium": 8.0,
    
    # Ideogram
    "ideogram/v2": 12.0,
    "ideogram/v2-turbo": 15.0,
    
    # Recraft
    "recraft/v3": 8.0,
    "recraft/crisp-upscale": 12.0,
    "recraft/remove-background": 8.0,
    
    # Video generation
    "google/veo-3": 150.0,
    "google/veo-3.1": 180.0,
    "kling/v1-standard": 80.0,
    "kling/v1-pro": 120.0,
    "kling/v1-image-to-video": 100.0,
    "hailuo/02-text-to-video-standard": 90.0,
    "luma/photon-1": 70.0,
    "runway/gen-3-alpha-turbo": 100.0,
    
    # Audio
    "elevenlabs/text-to-speech": 5.0,
    "elevenlabs/text-to-speech-multilingual-v2": 5.0,
    "elevenlabs/speech-to-text": 3.0,
    "elevenlabs/sound-effect": 8.0,
    "elevenlabs/sound-effect-v2": 8.0,
    "elevenlabs/audio-isolation": 5.0,
    "suno/v5": 25.0,
    
    # Upscale
    "topaz/image-upscale": 15.0,
    "topaz/video-upscale": 50.0,
    
    # ByteDance (–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω—ã–µ - –Ω–µ—Ç –Ω–∞ pricing page)
    "bytedance/seedance": 80.0,
    "bytedance/seedream": 10.0,
    "bytedance/seedream-v4-text-to-image": 12.0,
    "bytedance/v1-pro-image-to-video": 100.0,
    "bytedance/v1-lite-image-to-video": 60.0,
}

# –û–ø–∏—Å–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π (–Ω–∞ –æ—Å–Ω–æ–≤–µ https://kie.ai/models)
MODEL_DESCRIPTIONS = {
    "flux/pro": "High-quality text-to-image generation with Flux Pro",
    "flux/dev": "Fast text-to-image generation with Flux Dev",
    "flux-2/pro-text-to-image": "Flux 2 Pro - advanced text-to-image",
    "flux-2/flex-text-to-image": "Flex Flux 2 - balanced quality and speed",
    "flux-2/pro-image-to-image": "Flux 2 Pro image editing and transformation",
    "flux-2/flex-image-to-image": "Flex Flux 2 image-to-image processing",
    
    "stability/stable-diffusion-3-5-large": "Stable Diffusion 3.5 Large - high quality images",
    "stability/stable-diffusion-3-5-medium": "Stable Diffusion 3.5 Medium - balanced performance",
    
    "ideogram/v2": "Ideogram V2 - text rendering in images",
    "ideogram/v2-turbo": "Ideogram V2 Turbo - fast text-to-image",
    
    "recraft/v3": "Recraft V3 - vector style image generation",
    "recraft/crisp-upscale": "AI upscaling with crisp details",
    "recraft/remove-background": "Automatic background removal",
    
    "google/veo-3": "Google Veo 3 - advanced text-to-video",
    "google/veo-3.1": "Google Veo 3.1 - latest video generation",
    "kling/v1-standard": "Kling AI standard video generation",
    "kling/v1-pro": "Kling AI pro video generation",
    "kling/v1-image-to-video": "Kling AI image-to-video animation",
    
    "elevenlabs/text-to-speech": "ElevenLabs TTS - natural voice synthesis",
    "elevenlabs/speech-to-text": "ElevenLabs STT - accurate transcription",
    "elevenlabs/sound-effect": "AI sound effects generation",
    "elevenlabs/audio-isolation": "Isolate vocals or instruments",
    
    "suno/v5": "Suno V5 - AI music generation",
    
    "topaz/image-upscale": "Topaz AI image upscaling",
    "topaz/video-upscale": "Topaz AI video upscaling",
    
    "bytedance/seedance": "ByteDance Seedance - image-to-video",
    "bytedance/seedream": "ByteDance Seedream - text-to-image",
}


def generate_fallback_schema(category: str) -> Dict[str, Any]:
    """
    Generate intelligent fallback input_schema based on model category.
    
    MASTER PROMPT: "—Å–æ–∑–¥–∞—Ç—å fallback-schema —Å—Ç—Ä–æ–≥–æ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"
    
    Returns schema with required fields and properties for each category.
    """
    # Text-to-Image models: require prompt
    if category == "t2i":
        return {
            "required": ["prompt"],
            "optional": ["width", "height", "steps", "guidance_scale"],
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "Text description of the image to generate"
                },
                "width": {
                    "type": "integer",
                    "description": "Image width in pixels",
                    "default": 1024
                },
                "height": {
                    "type": "integer",
                    "description": "Image height in pixels",
                    "default": 1024
                },
                "steps": {
                    "type": "integer",
                    "description": "Number of inference steps",
                    "default": 20
                },
                "guidance_scale": {
                    "type": "number",
                    "description": "How strictly to follow the prompt",
                    "default": 7.5
                }
            }
        }
    
    # Image-to-Image: require url + prompt
    elif category == "i2i":
        return {
            "required": ["url", "prompt"],
            "optional": ["strength"],
            "properties": {
                "url": {
                    "type": "string",
                    "description": "URL of the source image"
                },
                "prompt": {
                    "type": "string",
                    "description": "Text description of desired changes"
                },
                "strength": {
                    "type": "number",
                    "description": "How much to change the image (0-1)",
                    "default": 0.8
                }
            }
        }
    
    # Text-to-Video: require prompt
    elif category == "t2v":
        return {
            "required": ["prompt"],
            "optional": ["duration", "fps", "resolution"],
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "Text description of the video"
                },
                "duration": {
                    "type": "number",
                    "description": "Video duration in seconds",
                    "default": 5
                },
                "fps": {
                    "type": "integer",
                    "description": "Frames per second",
                    "default": 24
                },
                "resolution": {
                    "type": "string",
                    "description": "Video resolution (720p, 1080p)",
                    "default": "1080p"
                }
            }
        }
    
    # Image-to-Video: require url
    elif category == "i2v":
        return {
            "required": ["url"],
            "optional": ["duration", "motion_strength"],
            "properties": {
                "url": {
                    "type": "string",
                    "description": "URL of the source image"
                },
                "duration": {
                    "type": "number",
                    "description": "Video duration in seconds",
                    "default": 5
                },
                "motion_strength": {
                    "type": "number",
                    "description": "Amount of motion (0-1)",
                    "default": 0.5
                }
            }
        }
    
    # Video-to-Video: require video_url
    elif category == "v2v":
        return {
            "required": ["video_url"],
            "optional": ["prompt"],
            "properties": {
                "video_url": {
                    "type": "string",
                    "description": "URL of the source video"
                },
                "prompt": {
                    "type": "string",
                    "description": "Description of desired transformation"
                }
            }
        }
    
    # Text-to-Speech: require text
    elif category == "tts":
        return {
            "required": ["text"],
            "optional": ["voice", "language"],
            "properties": {
                "text": {
                    "type": "string",
                    "description": "Text to convert to speech"
                },
                "voice": {
                    "type": "string",
                    "description": "Voice ID or name"
                },
                "language": {
                    "type": "string",
                    "description": "Language code (en, ru, etc.)"
                }
            }
        }
    
    # Speech-to-Text: require audio_url
    elif category == "stt":
        return {
            "required": ["audio_url"],
            "optional": ["language"],
            "properties": {
                "audio_url": {
                    "type": "string",
                    "description": "URL of the audio file"
                },
                "language": {
                    "type": "string",
                    "description": "Expected language (optional)"
                }
            }
        }
    
    # Audio effects/music: require prompt
    elif category in ["music", "sfx"]:
        return {
            "required": ["prompt"],
            "optional": ["duration"],
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "Description of the audio to generate"
                },
                "duration": {
                    "type": "number",
                    "description": "Duration in seconds",
                    "default": 10
                }
            }
        }
    
    # Audio isolation: require audio_url
    elif category == "audio_isolation":
        return {
            "required": ["audio_url"],
            "optional": ["target"],
            "properties": {
                "audio_url": {
                    "type": "string",
                    "description": "URL of the audio file"
                },
                "target": {
                    "type": "string",
                    "description": "What to isolate (vocals, instruments, etc.)"
                }
            }
        }
    
    # Upscale: require url
    elif category == "upscale":
        return {
            "required": ["url"],
            "optional": ["scale"],
            "properties": {
                "url": {
                    "type": "string",
                    "description": "URL of the image or video to upscale"
                },
                "scale": {
                    "type": "number",
                    "description": "Upscale factor (2x, 4x)",
                    "default": 2
                }
            }
        }
    
    # Background removal: require url
    elif category == "bg_remove":
        return {
            "required": ["url"],
            "optional": [],
            "properties": {
                "url": {
                    "type": "string",
                    "description": "URL of the image"
                }
            }
        }
    
    # Watermark removal: require url
    elif category == "watermark_remove":
        return {
            "required": ["url"],
            "optional": [],
            "properties": {
                "url": {
                    "type": "string",
                    "description": "URL of the image or video"
                }
            }
        }
    
    # Lip sync: require video_url + audio_url
    elif category == "lip_sync":
        return {
            "required": ["video_url", "audio_url"],
            "optional": [],
            "properties": {
                "video_url": {
                    "type": "string",
                    "description": "URL of the video with face"
                },
                "audio_url": {
                    "type": "string",
                    "description": "URL of the target speech audio"
                }
            }
        }
    
    # Default fallback: simple prompt
    else:
        return {
            "required": ["prompt"],
            "optional": [],
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "Input text or description"
                }
            }
        }


# –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–µ –∏–º–µ–Ω–∞
MODEL_NAMES = {
    "flux/pro": "Flux Pro",
    "flux/dev": "Flux Dev",
    "flux-2/pro-text-to-image": "Flux 2 Pro (Text)",
    "flux-2/flex-text-to-image": "Flux 2 Flex (Text)",
    "flux-2/pro-image-to-image": "Flux 2 Pro (Image)",
    "flux-2/flex-image-to-image": "Flux 2 Flex (Image)",
    
    "stability/stable-diffusion-3-5-large": "Stable Diffusion 3.5 Large",
    "stability/stable-diffusion-3-5-medium": "Stable Diffusion 3.5 Medium",
    
    "ideogram/v2": "Ideogram V2",
    "ideogram/v2-turbo": "Ideogram V2 Turbo",
    
    "recraft/v3": "Recraft V3",
    "recraft/crisp-upscale": "Recraft Crisp Upscale",
    "recraft/remove-background": "Recraft Background Remove",
    
    "google/veo-3": "Google Veo 3",
    "google/veo-3.1": "Google Veo 3.1",
    "kling/v1-standard": "Kling Standard",
    "kling/v1-pro": "Kling Pro",
    "kling/v1-image-to-video": "Kling Image-to-Video",
    
    "elevenlabs/text-to-speech": "ElevenLabs TTS",
    "elevenlabs/speech-to-text": "ElevenLabs STT",
    "elevenlabs/sound-effect": "ElevenLabs SFX",
    "elevenlabs/audio-isolation": "Audio Isolation",
    
    "suno/v5": "Suno V5",
    
    "topaz/image-upscale": "Topaz Image Upscale",
    "topaz/video-upscale": "Topaz Video Upscale",
}


def enrich_model(model: Dict[str, Any]) -> Dict[str, Any]:
    """Enrich single model with price, description, name, and input_schema."""
    model_id = model.get("model_id", "")
    category = model.get("category", "")
    
    # Skip processors and constants
    if any(x in model_id.lower() for x in ["processor", "test"]) or model_id.isupper():
        return model
    
    # PRICING STRATEGY (MASTER PROMPT COMPLIANCE):
    # 1. Official prices first (from Kie.ai)
    # 2. Intelligent fallback by category (NO model left behind)
    # 3. ALL models MUST be enabled
    if model_id in OFFICIAL_PRICES_RUB:
        model["price"] = OFFICIAL_PRICES_RUB[model_id]
        model["is_pricing_known"] = True
    else:
        # INTELLIGENT FALLBACK - estimate by category
        # MASTER PROMPT: "–ù–ò –û–î–ù–ê –º–æ–¥–µ–ª—å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∫—Ä—ã—Ç–∞"
        fallback_prices_by_category = {
            "t2i": 12.0,          # Text-to-image (medium complexity)
            "i2i": 15.0,          # Image-to-image (higher processing)
            "t2v": 100.0,         # Text-to-video (expensive)
            "i2v": 90.0,          # Image-to-video (very expensive)
            "v2v": 95.0,          # Video-to-video (expensive)
            "tts": 5.0,           # Text-to-speech (cheap)
            "stt": 3.0,           # Speech-to-text (cheapest)
            "music": 25.0,        # Music generation (medium-high)
            "sfx": 8.0,           # Sound effects (low-medium)
            "audio_isolation": 5.0,  # Audio processing (cheap)
            "upscale": 15.0,      # Upscaling (medium)
            "bg_remove": 8.0,     # Background removal (low-medium)
            "watermark_remove": 10.0,  # Watermark removal (medium)
            "lip_sync": 20.0,     # Lip sync (medium-high)
            "general": 10.0,      # General purpose (medium)
            "other": 15.0,        # Unknown (medium-high)
        }
        
        estimated_price = fallback_prices_by_category.get(category, 15.0)
        model["price"] = estimated_price
        model["is_pricing_known"] = False
        model["pricing_source"] = "category_fallback"
    
    # INTELLIGENT INPUT_SCHEMA GENERATION (MASTER PROMPT COMPLIANCE)
    # "—Å–æ–∑–¥–∞—Ç—å fallback-schema —Å—Ç—Ä–æ–≥–æ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"
    current_schema = model.get("input_schema", {})
    has_required = current_schema.get("required")
    has_properties = current_schema.get("properties")
    
    # If schema is empty or incomplete, generate fallback
    if not has_required and not has_properties:
        fallback_schema = generate_fallback_schema(category)
        model["input_schema"] = fallback_schema
        model["schema_source"] = "category_fallback"
    
    # Add description if known
    if model_id in MODEL_DESCRIPTIONS and not model.get("description"):
        model["description"] = MODEL_DESCRIPTIONS[model_id]
    elif not model.get("description"):
        # Generate basic description from category and name
        cat_desc = {
            "t2i": "text-to-image generation",
            "i2i": "image-to-image transformation",
            "t2v": "text-to-video generation",
            "i2v": "image-to-video animation",
            "v2v": "video-to-video transformation",
            "tts": "text-to-speech synthesis",
            "stt": "speech-to-text transcription",
            "music": "music generation",
            "sfx": "sound effects generation",
            "upscale": "AI upscaling",
            "bg_remove": "background removal",
            "audio_isolation": "audio isolation",
        }.get(category, "AI processing")
        
        model_name = model.get("name", model_id.split("/")[-1])
        model["description"] = f"{model_name} - {cat_desc}"
    
    # Add human-readable name
    if model_id in MODEL_NAMES and "name" not in model:
        model["name"] = MODEL_NAMES[model_id]
    elif "name" not in model:
        # Generate name from model_id
        model["name"] = model_id.replace("/", " ").replace("-", " ").title()
    
    return model


def main():
    """Enrich registry with official data."""
    repo_root = Path(__file__).parent.parent
    registry_path = repo_root / "models" / "kie_models_source_of_truth.json"
    
    print("=" * 60)
    print("ENRICHING REGISTRY WITH OFFICIAL DATA")
    print("=" * 60)
    print(f"Source: {registry_path}")
    print()
    
    with open(registry_path) as f:
        data = json.load(f)
    
    models = data.get("models", [])
    enriched_count = 0
    known_pricing = 0
    unknown_pricing = 0
    
    for i, model in enumerate(models):
        original = model.copy()
        enriched = enrich_model(model)
        
        # Check if anything changed
        if enriched != original:
            enriched_count += 1
            models[i] = enriched
        
        # Count pricing status
        if enriched.get("is_pricing_known"):
            known_pricing += 1
        elif not any(x in enriched.get("model_id", "").lower() for x in ["processor", "test"]):
            if not enriched.get("model_id", "").isupper():
                unknown_pricing += 1
    
    data["models"] = models
    
    # Save back
    with open(registry_path, "w") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Enriched {enriched_count} models")
    print(f"üí∞ Known pricing: {known_pricing} models")
    print(f"‚ö†Ô∏è  Unknown pricing: {unknown_pricing} models (DISABLED)")
    print(f"üìù Updated registry: {registry_path}")
    print()
    if unknown_pricing > 0:
        print("‚ö†Ô∏è  Models without pricing will be disabled in UI")
        print("    Users will see: '–ú–æ–¥–µ–ª—å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞'")
    print()
    print("Run 'python scripts/kie_truth_audit.py' to verify")


if __name__ == "__main__":
    main()
