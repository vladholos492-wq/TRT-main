#!/usr/bin/env python3
"""
–ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å KIE.ai Market.
–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å —Ç–µ–∫—É—â–∏–º–∏, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ.
"""

import os
import sys
import asyncio
import json
from pathlib import Path
from typing import Dict, List, Any, Set, Optional
from dotenv import load_dotenv

root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

load_dotenv()

import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def fetch_all_models_from_api() -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ KIE API."""
    try:
        from kie_client import get_client
        
        client = get_client()
        models = await client.list_models()
        
        if not models:
            logger.warning("‚ö†Ô∏è API –Ω–µ –≤–µ—Ä–Ω—É–ª –º–æ–¥–µ–ª–∏")
            return []
        
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –∏–∑ API")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        detailed_models = []
        for model in models:
            model_id = model.get('id') or model.get('model_id') or model.get('name', '')
            if not model_id:
                continue
            
            model_details = await client.get_model(model_id)
            if model_details:
                detailed_models.append({**model, **model_details})
            else:
                detailed_models.append(model)
        
        return detailed_models
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π: {e}", exc_info=True)
        return []


def load_current_models() -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ kie_models.py."""
    try:
        from kie_models import KIE_MODELS
        return KIE_MODELS
    except ImportError:
        try:
            from kie_models_new import KIE_MODELS
            return KIE_MODELS
        except ImportError:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –º–æ–¥–µ–ª–∏")
            return []


def extract_modes_from_api_model(api_model: Dict[str, Any]) -> List[Dict[str, Any]]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ modes –∏–∑ –º–æ–¥–µ–ª–∏ API."""
    modes = []
    
    model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
    model_types = api_model.get('model_types', [])
    input_schema = api_model.get('input_schema') or api_model.get('inputSchema') or {}
    
    if model_types:
        for model_type in model_types:
            type_id = model_type.get('id') or model_type.get('type_id') or model_type.get('name', '')
            type_schema = model_type.get('input_schema') or model_type.get('inputSchema') or input_schema
            
            generation_type = determine_generation_type(type_id, type_schema)
            
            mode = {
                "model": model_id,
                "generation_type": generation_type,
                "category": determine_category(generation_type),
                "input_schema": normalize_input_schema(type_schema),
                "pricing_unit": determine_pricing_unit(generation_type, type_schema),
                "help": model_type.get('description') or model_type.get('help') or api_model.get('description', '')
            }
            
            modes.append({
                "mode_id": type_id or generation_type,
                "mode_data": mode
            })
    else:
        generation_type = determine_generation_type(model_id, input_schema)
        
        mode = {
            "model": model_id,
            "generation_type": generation_type,
            "category": determine_category(generation_type),
            "input_schema": normalize_input_schema(input_schema),
            "pricing_unit": determine_pricing_unit(generation_type, input_schema),
            "help": api_model.get('description') or api_model.get('help', '')
        }
        
        modes.append({
            "mode_id": generation_type,
            "mode_data": mode
        })
    
    return modes


def determine_generation_type(model_id: str, input_schema: Dict[str, Any]) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."""
    model_id_lower = model_id.lower()
    
    if 'text-to-video' in model_id_lower:
        return 'text_to_video'
    elif 'image-to-video' in model_id_lower:
        return 'image_to_video'
    elif 'video-to-video' in model_id_lower:
        return 'video_to_video'
    elif 'text-to-image' in model_id_lower:
        return 'text_to_image'
    elif 'image-to-image' in model_id_lower:
        return 'image_to_image'
    elif 'edit' in model_id_lower:
        return 'image_edit'
    elif 'upscale' in model_id_lower:
        return 'image_upscale'
    elif 'watermark' in model_id_lower:
        return 'video_edit'
    elif 'music' in model_id_lower:
        return 'music_generation'
    
    properties = input_schema.get('properties', {})
    
    if 'video_url' in properties:
        return 'video_to_video'
    elif 'image_url' in properties or 'image_input' in properties:
        if 'prompt' in properties:
            return 'image_to_video' if 'duration' in properties else 'image_to_image'
        else:
            return 'image_upscale'
    elif 'prompt' in properties:
        return 'text_to_video' if 'duration' in properties else 'text_to_image'
    
    return 'unknown'


def determine_category(generation_type: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é."""
    if 'video' in generation_type:
        return 'Video'
    elif 'image' in generation_type:
        return 'Image'
    elif 'audio' in generation_type or 'music' in generation_type:
        return 'Audio'
    else:
        return 'Tools'


def determine_pricing_unit(generation_type: str, input_schema: Dict[str, Any]) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –µ–¥–∏–Ω–∏—Ü—É —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è."""
    if 'video' in generation_type:
        return 'per_5s'
    elif 'image' in generation_type:
        return 'per_image'
    else:
        return 'per_use'


def normalize_input_schema(schema: Dict[str, Any]) -> Dict[str, Any]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç input_schema."""
    if not schema:
        return {"type": "object", "properties": {}, "required": []}
    
    if 'type' in schema and schema.get('type') == 'object':
        return schema
    
    if 'input_params' in schema:
        properties = {}
        required = []
        
        for param_name, param_data in schema['input_params'].items():
            prop = {
                "type": param_data.get('type', 'string'),
                "description": param_data.get('description', '')
            }
            
            if 'enum' in param_data:
                prop['enum'] = param_data['enum']
            if 'default' in param_data:
                prop['default'] = param_data['default']
            if 'max_length' in param_data:
                prop['maxLength'] = param_data['max_length']
            
            properties[param_name] = prop
            
            if param_data.get('required', False):
                required.append(param_name)
        
        return {
            "type": "object",
            "properties": properties,
            "required": required
        }
    
    return schema


def compare_and_find_new_models(
    api_models: List[Dict[str, Any]],
    current_models: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç API –º–æ–¥–µ–ª–∏ —Å —Ç–µ–∫—É—â–∏–º–∏ –∏ –Ω–∞—Ö–æ–¥–∏—Ç –Ω–æ–≤—ã–µ."""
    current_model_ids = {m.get('id', '') for m in current_models if m.get('id')}
    
    new_models = []
    new_modes = {}
    new_parameters = {}
    
    for api_model in api_models:
        model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
        if not model_id:
            continue
        
        if model_id not in current_model_ids:
            # –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å
            new_models.append(api_model)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º modes
            modes = extract_modes_from_api_model(api_model)
            new_modes[model_id] = modes
        else:
            # –ú–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º modes
            current_model = next((m for m in current_models if m.get('id') == model_id), None)
            if current_model:
                api_modes = extract_modes_from_api_model(api_model)
                current_mode_ids = set()
                
                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—É—â–∏–µ mode IDs
                if 'modes' in current_model:
                    current_mode_ids = set(current_model['modes'].keys())
                elif 'generation_type' in current_model:
                    current_mode_ids = {current_model['generation_type']}
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ modes
                for mode_info in api_modes:
                    mode_id = mode_info['mode_id']
                    if mode_id not in current_mode_ids:
                        if model_id not in new_modes:
                            new_modes[model_id] = []
                        new_modes[model_id].append(mode_info)
    
    return {
        "new_models": new_models,
        "new_modes": new_modes,
        "new_parameters": new_parameters
    }


def auto_add_new_models_to_kie_models(
    new_data: Dict[str, Any],
    kie_models_file: Path
) -> bool:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –≤ kie_models.py."""
    try:
        # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª
        with open(kie_models_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
        backup_file = kie_models_file.with_suffix('.py.backup')
        with open(backup_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_file}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
        new_models_code = []
        
        for api_model in new_data['new_models']:
            model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
            modes = extract_modes_from_api_model(api_model)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–¥ –¥–ª—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            model_code = f"""
    {{
        "id": "{model_id}",
        "name": "{api_model.get('title', api_model.get('name', model_id))}",
        "description": "{api_model.get('description', '')}",
        "category": "{determine_category(modes[0]['mode_data']['generation_type']) if modes else 'Other'}",
        "modes": {{
"""
            
            for mode_info in modes:
                mode_id = mode_info['mode_id']
                mode_data = mode_info['mode_data']
                
                model_code += f"""
            "{mode_id}": {{
                "model": "{mode_data['model']}",
                "generation_type": "{mode_data['generation_type']}",
                "category": "{mode_data['category']}",
                "input_schema": {json.dumps(mode_data['input_schema'], ensure_ascii=False, indent=16)},
                "pricing_unit": "{mode_data['pricing_unit']}",
                "help": "{mode_data['help']}"
            }},
"""
            
            model_code += """
        }
    },
"""
            new_models_code.append(model_code)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–æ–π
        if ']' in content:
            content = content.rstrip()
            if content.endswith(']'):
                content = content[:-1]
                content += ',\n'.join(new_models_code)
                content += '\n]'
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Ñ–∞–π–ª
        with open(kie_models_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_data['new_models'])} –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ {kie_models_file}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π: {e}", exc_info=True)
        return False


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏."""
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å KIE.ai Market...")
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ API
    api_models = await fetch_all_models_from_api()
    
    if not api_models:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ API")
        return 1
    
    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ –º–æ–¥–µ–ª–∏
    current_models = load_current_models()
    
    # 3. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏ –Ω–∞—Ö–æ–¥–∏–º –Ω–æ–≤—ã–µ
    new_data = compare_and_find_new_models(api_models, current_models)
    
    # 4. –í—ã–≤–æ–¥–∏–º –æ—Ç—á—ë—Ç
    print("\n" + "="*80)
    print("üìä –û–¢–ß–Å–¢ –ü–û–õ–ù–û–ô –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–ò")
    print("="*80)
    
    print(f"\nüìã –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  –ú–æ–¥–µ–ª–µ–π –≤ API: {len(api_models)}")
    print(f"  –ú–æ–¥–µ–ª–µ–π –ª–æ–∫–∞–ª—å–Ω–æ: {len(current_models)}")
    print(f"  –ù–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: {len(new_data['new_models'])}")
    
    total_new_modes = sum(len(modes) for modes in new_data['new_modes'].values())
    print(f"  –ù–æ–≤—ã—Ö modes: {total_new_modes}")
    
    if new_data['new_models']:
        print(f"\nüÜï –ù–û–í–´–ï –ú–û–î–ï–õ–ò:")
        for model in new_data['new_models']:
            model_id = model.get('id') or model.get('model_id') or model.get('name', '')
            print(f"  - {model_id}")
    
    if new_data['new_modes']:
        print(f"\nüÜï –ù–û–í–´–ï MODES:")
        for model_id, modes in new_data['new_modes'].items():
            print(f"  {model_id}:")
            for mode_info in modes:
                print(f"    - {mode_info['mode_id']}")
    
    # 5. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
    if new_data['new_models']:
        kie_models_file = root_dir / "kie_models.py"
        if kie_models_file.exists():
            print(f"\nüíæ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π...")
            success = auto_add_new_models_to_kie_models(new_data, kie_models_file)
            if success:
                print("‚úÖ –ù–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã!")
            else:
                print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π")
        else:
            print(f"\n‚ö†Ô∏è –§–∞–π–ª {kie_models_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    print("\n" + "="*80)
    
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

