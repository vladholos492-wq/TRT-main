#!/usr/bin/env python3
"""
KIE Verify Parser - –±–µ–∑–æ–ø–∞—Å–Ω–∞—è —Å–≤–µ—Ä–∫–∞ upstream Kie.ai docs —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ä–µ–µ—Å—Ç—Ä–æ–º.

–ü–†–ê–í–ò–õ–ê:
- –ù–ï –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- –¢–æ–ª—å–∫–æ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏
- –ù–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –∫–∞–∫ "candidates" –∏ —Ç—Ä–µ–±—É—é—Ç —è–≤–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
- –¶–µ–Ω—ã: upstream_usd -> our_rub = round(upstream_usd * USD_TO_RUB * 2)
"""

import sys
import os
import json
import re
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass, asdict

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Import KIE config (–µ–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è USD_TO_RUB)
from scripts.kie_config import get_usd_to_rub_rate, calculate_rub_price, KIEConfigError


@dataclass
class UpstreamModelInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –∏–∑ upstream (Kie.ai docs)."""
    model_id: str
    input_schema: Dict[str, Any]  # name -> {required, type, default, options, constraints}
    upstream_usd_price: Optional[float] = None
    docs_url: Optional[str] = None
    fetched_at: Optional[str] = None


@dataclass
class ModelDiff:
    """–†–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É upstream –∏ –ª–æ–∫–∞–ª—å–Ω—ã–º —Ä–µ–µ—Å—Ç—Ä–æ–º."""
    model_id: str
    exists_locally: bool
    schema_changes: List[str]  # –°–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Å—Ö–µ–º–µ
    price_changes: Optional[Dict[str, Any]] = None  # upstream_usd, our_current_rub, calculated_rub
    is_new_model: bool = False


def load_local_registry() -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä –º–æ–¥–µ–ª–µ–π."""
    # –ò—â–µ–º source of truth —Ñ–∞–π–ª
    possible_paths = [
        project_root / "models" / "KIE_SOURCE_OF_TRUTH.json",
        project_root / "models" / "kie_models.json",
        project_root / "app" / "kie" / "models_registry.json",
    ]
    
    for path in possible_paths:
        if path.exists():
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
    
    print("‚ö†Ô∏è  Local registry not found, using empty dict")
    return {}


def parse_kie_docs_html(html_content: str, model_id: str) -> Optional[UpstreamModelInfo]:
    """
    –ü–∞—Ä—Å–∏—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É Kie.ai docs –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏.
    
    –ò—â–µ—Ç:
    - model_id –∏–∑ JSON –ø—Ä–∏–º–µ—Ä–æ–≤: "model": "..."
    - input schema –∏–∑ —Ç–∞–±–ª–∏—Ü "Input Object Parameters" –∏–ª–∏ JSON body
    - —Ü–µ–Ω—ã –∏–∑ —Ç–∞–±–ª–∏—Ü –∏–ª–∏ JSON –ø—Ä–∏–º–µ—Ä–æ–≤
    """
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        print("‚ö†Ô∏è  BeautifulSoup not available, skipping HTML parsing")
        return None
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º model_id –∏–∑ JSON –ø—Ä–∏–º–µ—Ä–æ–≤
    found_model_id = None
    json_blocks = soup.find_all(['code', 'pre'], string=re.compile(r'"model"\s*:\s*"([^"]+)"'))
    for block in json_blocks:
        match = re.search(r'"model"\s*:\s*"([^"]+)"', block.get_text())
        if match:
            found_model_id = match.group(1)
            break
    
    if not found_model_id:
        # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π model_id
        found_model_id = model_id
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º input schema –∏–∑ —Ç–∞–±–ª–∏—Ü
    input_schema = {}
    
    # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—ã —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    tables = soup.find_all('table')
    for table in tables:
        headers = [th.get_text().strip().lower() for th in table.find_all('th')]
        if 'parameter' in headers or 'field' in headers or 'name' in headers:
            rows = table.find_all('tr')[1:]  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            for row in rows:
                cells = [td.get_text().strip() for td in row.find_all(['td', 'th'])]
                if len(cells) >= 2:
                    field_name = cells[0]
                    field_info = {
                        "required": "required" in " ".join(cells).lower(),
                        "type": cells[1] if len(cells) > 1 else "string",
                        "default": None,
                        "options": [],
                    }
                    input_schema[field_name] = field_info
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
    upstream_usd_price = None
    price_patterns = [
        r'\$(\d+\.?\d*)\s*(?:USD|usd)',
        r'(\d+\.?\d*)\s*(?:USD|usd)',
        r'price[:\s]+(\d+\.?\d*)',
    ]
    text = soup.get_text()
    for pattern in price_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            try:
                upstream_usd_price = float(match.group(1))
                break
            except ValueError:
                continue
    
    return UpstreamModelInfo(
        model_id=found_model_id,
        input_schema=input_schema,
        upstream_usd_price=upstream_usd_price,
        docs_url=None,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ
        fetched_at=datetime.now().isoformat()
    )


def compare_with_local(
    upstream_info: UpstreamModelInfo,
    local_registry: Dict[str, Any],
    verify_only: bool = True
) -> Optional[ModelDiff]:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç upstream –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –ª–æ–∫–∞–ª—å–Ω—ã–º —Ä–µ–µ—Å—Ç—Ä–æ–º.
    
    Args:
        upstream_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –∏–∑ upstream
        local_registry: –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä –º–æ–¥–µ–ª–µ–π
        verify_only: –ï—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ —Å–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏, –Ω–æ–≤—ã–µ –ø–æ–º–µ—á–∞–µ—Ç –∫–∞–∫ candidates
    
    Returns:
        ModelDiff –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ –∏–ª–∏ verify_only=False, None –µ—Å–ª–∏ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –∏ verify_only=True
    """
    model_id = upstream_info.model_id
    
    # –ò—â–µ–º –º–æ–¥–µ–ª—å –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ä–µ–µ—Å—Ç—Ä–µ
    local_model = None
    if "models" in local_registry:
        for model in local_registry["models"]:
            if model.get("model_id") == model_id:
                local_model = model
                break
    
    exists_locally = local_model is not None
    
    # –í —Ä–µ–∂–∏–º–µ verify-only –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (–æ–Ω–∏ –±—É–¥—É—Ç –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫ candidates –æ—Ç–¥–µ–ª—å–Ω–æ)
    if verify_only and not exists_locally:
        return None  # –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å, –Ω–µ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    
    schema_changes = []
    price_changes = None
    
    if exists_locally:
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å—Ö–µ–º—É
        local_schema = local_model.get("input_schema", {})
        for field_name, upstream_field in upstream_info.input_schema.items():
            local_field = local_schema.get(field_name)
            if not local_field:
                schema_changes.append(f"New field in upstream: {field_name}")
            else:
                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º required
                if upstream_field.get("required") != local_field.get("required"):
                    schema_changes.append(
                        f"Field {field_name}: required changed from {local_field.get('required')} to {upstream_field.get('required')}"
                    )
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ü–µ–Ω—ã
        if upstream_info.upstream_usd_price:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–∑–∞–ø—Ä–µ—â–∞–µ—Ç —Ç–∏—Ö–∏–µ –¥–µ—Ñ–æ–ª—Ç—ã)
                calculated_rub = calculate_rub_price(upstream_info.upstream_usd_price, markup_multiplier=2.0)
                local_price = local_model.get("pricing", {}).get("rub_per_gen")
                if local_price and local_price != calculated_rub:
                    price_changes = {
                        "upstream_usd": upstream_info.upstream_usd_price,
                        "our_current_rub": local_price,
                        "calculated_rub": calculated_rub,
                        "difference": calculated_rub - local_price
                    }
            except KIEConfigError as e:
                # –ù–µ –º–æ–ª—á–∏–º - –≤—ã–≤–æ–¥–∏–º –æ—à–∏–±–∫—É, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É
                print(f"‚ö†Ô∏è  Price calculation skipped: {e}")
                schema_changes.append(f"Price calculation failed: USD_TO_RUB not configured")
    else:
        # –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ verify_only=False)
        schema_changes.append("NEW MODEL - not in local registry")
    
    return ModelDiff(
        model_id=model_id,
        exists_locally=exists_locally,
        schema_changes=schema_changes,
        price_changes=price_changes,
        is_new_model=not exists_locally
    )


def fetch_kie_docs_page(url: str) -> Optional[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É Kie.ai docs."""
    try:
        import requests
        resp = requests.get(url, timeout=15)
        if resp.status_code == 200:
            return resp.text
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to fetch {url}: {e}")
        return None


def main():
    """Main function."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Verify KIE models against upstream docs")
    parser.add_argument("--model-id", help="Specific model ID to check")
    parser.add_argument("--docs-url", help="URL to Kie.ai docs page")
    parser.add_argument("--html-file", help="Local HTML file instead of URL")
    parser.add_argument("--verify-only", action="store_true", 
                       help="Verify-only mode: only check existing models, mark new ones as candidates")
    parser.add_argument("--allow-new", action="store_true",
                       help="Allow processing new models (default: verify-only mode)")
    
    args = parser.parse_args()
    
    print("="*60)
    print("  KIE VERIFY PARSER")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä
    local_registry = load_local_registry()
    print(f"‚úÖ Loaded local registry ({len(local_registry.get('models', []))} models)")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º: verify_only –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω --allow-new
    verify_only_mode = not args.allow_new
    
    if args.verify_only and not args.docs_url and not args.html_file:
        print("‚ÑπÔ∏è  Verify-only mode: no upstream fetch (use --docs-url or --html-file to fetch)")
        print("   Loading existing candidates...")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ candidates
        artifacts_dir = project_root / "artifacts"
        candidates_file = artifacts_dir / "kie_model_candidates.json"
        if candidates_file.exists():
            with open(candidates_file, 'r', encoding='utf-8') as f:
                candidates = json.load(f)
            print(f"   Found {len(candidates)} candidate models:")
            for c in candidates:
                print(f"     - {c.get('model_id')} (added: {c.get('added_at', 'unknown')})")
        else:
            print("   No candidates found")
        return 0
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω HTML —Ñ–∞–π–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    html_content = None
    if args.html_file:
        with open(args.html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
    elif args.docs_url:
        print(f"üì• Fetching {args.docs_url}...")
        html_content = fetch_kie_docs_page(args.docs_url)
    
    if not html_content:
        print("‚ùå No HTML content available")
        return 1
    
    # –ü–∞—Ä—Å–∏–º
    model_id = args.model_id or "unknown"
    upstream_info = parse_kie_docs_html(html_content, model_id)
    
    if not upstream_info:
        print("‚ùå Failed to parse upstream info")
        return 1
    
    print(f"‚úÖ Parsed upstream info for {upstream_info.model_id}")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º (verify_only_mode –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏)
    diff = compare_with_local(upstream_info, local_registry, verify_only=verify_only_mode)
    
    # –ï—Å–ª–∏ verify_only_mode –∏ –º–æ–¥–µ–ª—å –Ω–æ–≤–∞—è - –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ candidate
    if verify_only_mode and diff is None:
        # –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å - –¥–æ–±–∞–≤–ª—è–µ–º –≤ candidates
        artifacts_dir = project_root / "artifacts"
        artifacts_dir.mkdir(exist_ok=True)
        
        candidates_file = artifacts_dir / "kie_model_candidates.json"
        candidates = []
        if candidates_file.exists():
            with open(candidates_file, 'r', encoding='utf-8') as f:
                candidates = json.load(f)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π –º–æ–¥–µ–ª–∏ –≤ candidates
        if not any(c.get("model_id") == upstream_info.model_id for c in candidates):
            candidate = {
                "model_id": upstream_info.model_id,
                "upstream_info": asdict(upstream_info),
                "added_at": datetime.now().isoformat(),
                "status": "candidate",
                "note": "New model from upstream, requires manual review"
            }
            candidates.append(candidate)
            
            with open(candidates_file, 'w', encoding='utf-8') as f:
                json.dump(candidates, f, indent=2, ensure_ascii=False)
            
            print(f"\n‚úÖ New model marked as CANDIDATE: {upstream_info.model_id}")
            print(f"üíæ Candidates saved to {candidates_file}")
            return 0
    
    if diff is None:
        print("‚ö†Ô∏è  Model not found locally and verify_only mode enabled (skipped, marked as candidate)")
        return 0
    
    # –í—ã–≤–æ–¥–∏–º diff –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π
    print("\n" + "="*60)
    print("  DIFF REPORT")
    print("="*60)
    print(f"Model ID: {diff.model_id}")
    print(f"Exists locally: {diff.exists_locally}")
    print(f"Is new model: {diff.is_new_model}")
    
    if diff.schema_changes:
        print("\nSchema changes:")
        for change in diff.schema_changes:
            print(f"  - {change}")
    
    if diff.price_changes:
        print("\nPrice changes:")
        print(f"  Upstream USD: ${diff.price_changes['upstream_usd']}")
        print(f"  Our current RUB: ‚ÇΩ{diff.price_changes['our_current_rub']}")
        print(f"  Calculated RUB: ‚ÇΩ{diff.price_changes['calculated_rub']}")
        print(f"  Difference: ‚ÇΩ{diff.price_changes['difference']}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º snapshot
    artifacts_dir = project_root / "artifacts"
    artifacts_dir.mkdir(exist_ok=True)
    
    snapshot = {
        "fetched_at": datetime.now().isoformat(),
        "model_id": upstream_info.model_id,
        "upstream_info": asdict(upstream_info),
        "diff": asdict(diff),
        "verify_only": verify_only_mode
    }
    
    snapshot_file = artifacts_dir / f"kie_upstream_snapshot_{upstream_info.model_id.replace('/', '_')}.json"
    with open(snapshot_file, 'w', encoding='utf-8') as f:
        json.dump(snapshot, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Snapshot saved to {snapshot_file}")
    
    return 0


if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except Exception as e:
        print(f"‚ùå Fatal error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

