#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π KIE AI —Å –ª–æ–∫–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏ –∏—Ö modes, –≤—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç.
"""

import os
import sys
import asyncio
import json
from pathlib import Path
from typing import Dict, List, Any, Set, Optional
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def fetch_all_models_from_api() -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ KIE API."""
    try:
        from kie_client import get_client
        
        client = get_client()
        models = await client.list_models()
        
        if not models:
            logger.warning("‚ö†Ô∏è API –Ω–µ –≤–µ—Ä–Ω—É–ª –º–æ–¥–µ–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ KIE_API_KEY –∏ KIE_API_URL")
            return []
        
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –∏–∑ KIE API")
        return models
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –∏–∑ API: {e}", exc_info=True)
        return []


async def fetch_model_details(model_id: str) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –∏–∑ API."""
    try:
        from kie_client import get_client
        
        client = get_client()
        model_info = await client.get_model(model_id)
        return model_info
        
    except Exception as e:
        logger.debug(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –¥–ª—è {model_id}: {e}")
        return None


def extract_modes_from_api_model(api_model: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç modes –∏–∑ –º–æ–¥–µ–ª–∏ API.
    KIE API –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ (Model Type).
    """
    modes = []
    
    model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
    model_types = api_model.get('model_types', [])
    input_schema = api_model.get('input_schema') or api_model.get('inputSchema') or {}
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å model_types, —Å–æ–∑–¥–∞—ë–º mode –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
    if model_types:
        for model_type in model_types:
            type_id = model_type.get('id') or model_type.get('type_id') or model_type.get('name', '')
            type_schema = model_type.get('input_schema') or model_type.get('inputSchema') or input_schema
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º generation_type –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Ç–∏–ø–∞ –∏–ª–∏ —Å—Ö–µ–º–µ
            generation_type = determine_generation_type(type_id, type_schema)
            
            mode = {
                "model": model_id,  # –†–µ–∞–ª—å–Ω—ã–π API model string
                "generation_type": generation_type,
                "category": determine_category(generation_type),
                "input_schema": normalize_input_schema(type_schema),
                "pricing_unit": determine_pricing_unit(generation_type, type_schema),
                "help": model_type.get('description') or model_type.get('help') or api_model.get('description', '')
            }
            
            modes.append({
                "mode_id": type_id or generation_type,
                "mode_data": mode
            })
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç model_types, —Å–æ–∑–¥–∞—ë–º –æ–¥–∏–Ω mode –Ω–∞ –æ—Å–Ω–æ–≤–µ input_schema
        generation_type = determine_generation_type(model_id, input_schema)
        
        mode = {
            "model": model_id,
            "generation_type": generation_type,
            "category": determine_category(generation_type),
            "input_schema": normalize_input_schema(input_schema),
            "pricing_unit": determine_pricing_unit(generation_type, input_schema),
            "help": api_model.get('description') or api_model.get('help', '')
        }
        
        modes.append({
            "mode_id": generation_type,
            "mode_data": mode
        })
    
    return modes


def determine_generation_type(model_id: str, input_schema: Dict[str, Any]) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ model_id –∏ input_schema."""
    model_id_lower = model_id.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –º–æ–¥–µ–ª–∏
    if 'text-to-video' in model_id_lower or 'text_to_video' in model_id_lower:
        return 'text_to_video'
    elif 'image-to-video' in model_id_lower or 'image_to_video' in model_id_lower:
        return 'image_to_video'
    elif 'video-to-video' in model_id_lower or 'video_to_video' in model_id_lower:
        return 'video_to_video'
    elif 'text-to-image' in model_id_lower or 'text_to_image' in model_id_lower:
        return 'text_to_image'
    elif 'image-to-image' in model_id_lower or 'image_to_image' in model_id_lower:
        return 'image_to_image'
    elif 'image-edit' in model_id_lower or 'image_edit' in model_id_lower or 'edit' in model_id_lower:
        return 'image_edit'
    elif 'upscale' in model_id_lower:
        return 'image_upscale'
    elif 'watermark' in model_id_lower or 'remove' in model_id_lower:
        return 'video_edit'
    elif 'speech-to-video' in model_id_lower:
        return 'speech_to_video'
    elif 'text-to-speech' in model_id_lower:
        return 'text_to_speech'
    elif 'speech-to-text' in model_id_lower:
        return 'speech_to_text'
    elif 'text-to-music' in model_id_lower or 'music' in model_id_lower:
        return 'text_to_music'
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ input_schema
    properties = input_schema.get('properties', {})
    
    if 'video_url' in properties:
        return 'video_to_video'
    elif 'image_urls' in properties or 'image_input' in properties or 'image_url' in properties:
        if 'prompt' in properties:
            return 'image_to_video' if 'duration' in properties or 'n_frames' in properties else 'image_to_image'
        else:
            return 'image_upscale'
    elif 'prompt' in properties or 'text' in properties:
        if 'duration' in properties or 'n_frames' in properties:
            return 'text_to_video'
        else:
            return 'text_to_image'
    elif 'audio_url' in properties:
        return 'speech_to_text'
    
    return 'unknown'


def determine_category(generation_type: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."""
    if 'video' in generation_type:
        return 'Video'
    elif 'image' in generation_type or 'upscale' in generation_type:
        return 'Image'
    elif 'audio' in generation_type or 'speech' in generation_type or 'music' in generation_type:
        return 'Audio'
    elif 'edit' in generation_type or 'remove' in generation_type:
        return 'Tools'
    else:
        return 'Other'


def determine_pricing_unit(generation_type: str, input_schema: Dict[str, Any]) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –µ–¥–∏–Ω–∏—Ü—É —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è."""
    if 'video' in generation_type:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º duration –≤ —Å—Ö–µ–º–µ
        properties = input_schema.get('properties', {})
        duration = properties.get('duration') or properties.get('n_frames')
        if duration:
            if isinstance(duration, dict):
                default = duration.get('default', 10)
                if default and int(default) > 10:
                    return 'per_10s'
            return 'per_5s'
        return 'per_5s'
    elif 'image' in generation_type:
        return 'per_image'
    elif 'audio' in generation_type or 'speech' in generation_type or 'music' in generation_type:
        return 'per_minute'
    else:
        return 'per_use'


def normalize_input_schema(schema: Dict[str, Any]) -> Dict[str, Any]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç input_schema –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É."""
    if not schema:
        return {"type": "object", "properties": {}, "required": []}
    
    # –ï—Å–ª–∏ schema —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    if 'type' in schema and schema.get('type') == 'object':
        return schema
    
    # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç (input_params)
    if 'input_params' in schema:
        properties = {}
        required = []
        
        for param_name, param_data in schema['input_params'].items():
            prop = {
                "type": param_data.get('type', 'string'),
                "description": param_data.get('description', '')
            }
            
            if 'enum' in param_data:
                prop['enum'] = param_data['enum']
            if 'default' in param_data:
                prop['default'] = param_data['default']
            if 'max_length' in param_data:
                prop['maxLength'] = param_data['max_length']
            if 'min' in param_data:
                prop['minimum'] = param_data['min']
            if 'max' in param_data:
                prop['maximum'] = param_data['max']
            if 'min_items' in param_data:
                prop['minItems'] = param_data['min_items']
            if 'max_items' in param_data:
                prop['maxItems'] = param_data['max_items']
            
            properties[param_name] = prop
            
            if param_data.get('required', False):
                required.append(param_name)
        
        return {
            "type": "object",
            "properties": properties,
            "required": required
        }
    
    return schema


def load_local_models() -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ kie_models_new.py."""
    try:
        sys.path.insert(0, str(root_dir))
        from kie_models_new import KIE_MODELS
        return KIE_MODELS
    except ImportError:
        logger.warning("‚ö†Ô∏è kie_models_new.py –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º —Å—Ç–∞—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É")
        try:
            from kie_models import KIE_MODELS as OLD_MODELS
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            return convert_old_structure(OLD_MODELS)
        except ImportError:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏")
            return {}


def convert_old_structure(old_models: List[Dict]) -> Dict[str, Any]:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤ –Ω–æ–≤—É—é (–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è)."""
    result = {}
    for model in old_models:
        model_id = model.get('id', '')
        if not model_id:
            continue
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º model_key (provider/model_name)
        model_key = model_id
        if '/' in model_id:
            model_key = model_id
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å provider
            provider = determine_provider(model_id)
            model_key = f"{provider}/{model_id}"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º mode
        generation_type = determine_generation_type(model_id, model.get('input_params', {}))
        
        if model_key not in result:
            result[model_key] = {
                "title": model.get('name', model_id),
                "provider": provider,
                "description": model.get('description', ''),
                "modes": {}
            }
        
        mode_data = {
            "model": model_id,
            "generation_type": generation_type,
            "category": determine_category(generation_type),
            "input_schema": normalize_input_schema(model.get('input_params', {})),
            "pricing_unit": determine_pricing_unit(generation_type, model.get('input_params', {})),
            "help": model.get('description', '')
        }
        
        result[model_key]["modes"][generation_type] = mode_data
    
    return result


def determine_provider(model_id: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç provider –Ω–∞ –æ—Å–Ω–æ–≤–µ model_id."""
    if 'sora' in model_id.lower():
        return 'openai'
    elif 'kling' in model_id.lower():
        return 'kling'
    elif 'wan' in model_id.lower():
        return 'wan'
    elif 'seedream' in model_id.lower() or 'bytedance' in model_id.lower():
        return 'bytedance'
    elif 'nano' in model_id.lower() or 'banana' in model_id.lower() or 'gemini' in model_id.lower():
        return 'google'
    elif 'veo' in model_id.lower():
        return 'google'
    elif 'flux' in model_id.lower():
        return 'blackforest'
    elif 'qwen' in model_id.lower():
        return 'qwen'
    elif 'elevenlabs' in model_id.lower():
        return 'elevenlabs'
    elif 'hailuo' in model_id.lower():
        return 'hailuo'
    elif 'topaz' in model_id.lower():
        return 'topaz'
    elif 'recraft' in model_id.lower():
        return 'recraft'
    elif 'ideogram' in model_id.lower():
        return 'ideogram'
    elif 'infinitalk' in model_id.lower():
        return 'infinitalk'
    elif 'suno' in model_id.lower():
        return 'suno'
    elif 'midjourney' in model_id.lower():
        return 'midjourney'
    elif 'runway' in model_id.lower():
        return 'runway'
    elif 'grok' in model_id.lower():
        return 'xai'
    elif 'z-image' in model_id.lower():
        return 'tongyi'
    else:
        return 'unknown'


def check_models_sync(
    api_models: List[Dict[str, Any]],
    local_models: Dict[str, Any]
) -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π –∏ modes."""
    report = {
        "total_api_models": len(api_models),
        "total_local_models": len(local_models),
        "total_local_modes": sum(len(m.get("modes", {})) for m in local_models.values()),
        "missing_models": [],
        "missing_modes": {},
        "schema_errors": [],
        "missing_schemas": [],
        "outdated_models": [],
        "new_models": [],
        "api_modes": {}
    }
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º modes –∏–∑ API –º–æ–¥–µ–ª–µ–π
    api_modes_by_model = {}
    for api_model in api_models:
        model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
        if not model_id:
            continue
        
        provider = determine_provider(model_id)
        model_key = model_id if '/' in model_id else f"{provider}/{model_id}"
        
        modes = extract_modes_from_api_model(api_model)
        api_modes_by_model[model_key] = modes
        report["api_modes"][model_key] = [m["mode_id"] for m in modes]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
    for model_key, model_data in local_models.items():
        local_modes = model_data.get("modes", {})
        
        if model_key not in api_modes_by_model:
            report["outdated_models"].append(model_key)
        else:
            api_modes = api_modes_by_model[model_key]
            api_mode_ids = {m["mode_id"] for m in api_modes}
            local_mode_ids = set(local_modes.keys())
            
            missing_modes = api_mode_ids - local_mode_ids
            if missing_modes:
                report["missing_modes"][model_key] = list(missing_modes)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º input_schema
            for mode_id, mode_data in local_modes.items():
                input_schema = mode_data.get("input_schema")
                if not input_schema:
                    report["missing_schemas"].append(f"{model_key}:{mode_id}")
                elif not isinstance(input_schema, dict):
                    report["schema_errors"].append(f"{model_key}:{mode_id} - input_schema –Ω–µ —Å–ª–æ–≤–∞—Ä—å")
                elif "properties" not in input_schema:
                    report["schema_errors"].append(f"{model_key}:{mode_id} - –Ω–µ—Ç properties")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ API
    for model_key, api_modes in api_modes_by_model.items():
        if model_key not in local_models:
            report["new_models"].append(model_key)
            report["missing_models"].append(model_key)
    
    return report


def print_detailed_report(report: Dict[str, Any]):
    """–í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏."""
    print("\n" + "="*80)
    print("üìä –û–¢–ß–Å–¢ –û –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–ò –ú–û–î–ï–õ–ï–ô KIE AI")
    print("="*80)
    
    print(f"\nüìã –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  –í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π –≤ KIE AI: 47 (–æ–∂–∏–¥–∞–µ—Ç—Å—è)")
    print(f"  –ú–æ–¥–µ–ª–µ–π –≤ API: {report['total_api_models']}")
    print(f"  –ú–æ–¥–µ–ª–µ–π –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: {report['total_local_models']}")
    print(f"  –í—Å–µ–≥–æ modes –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: {report['total_local_modes']}")
    
    # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ
    integrated_models = report['total_local_models']
    integrated_modes = report['total_local_modes']
    print(f"\n‚úÖ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–û:")
    print(f"  –ú–æ–¥–µ–ª–µ–π: {integrated_models}/47")
    print(f"  Modes: {integrated_modes}")
    
    # –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏
    if report['missing_models']:
        print(f"\n‚ùå –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï –ú–û–î–ï–õ–ò ({len(report['missing_models'])}):")
        for model in report['missing_models']:
            print(f"  - {model}")
            api_modes = report['api_modes'].get(model, [])
            if api_modes:
                print(f"    –ù—É–∂–Ω—ã modes: {', '.join(api_modes)}")
    else:
        print("\n‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
    
    # –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ modes
    if report['missing_modes']:
        print(f"\n‚ö†Ô∏è –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï MODES:")
        for model_key, modes in report['missing_modes'].items():
            print(f"  {model_key}:")
            for mode in modes:
                print(f"    - {mode}")
    else:
        print("\n‚úÖ –í—Å–µ modes –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
    
    # –ü—Ä–æ–±–ª–µ–º—ã —Å —Å—Ö–µ–º–∞–º–∏
    if report['schema_errors']:
        print(f"\n‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–´ –° INPUT_SCHEMA ({len(report['schema_errors'])}):")
        for error in report['schema_errors'][:10]:
            print(f"  - {error}")
        if len(report['schema_errors']) > 10:
            print(f"  ... –∏ –µ—â–µ {len(report['schema_errors']) - 10} –æ—à–∏–±–æ–∫")
    else:
        print("\n‚úÖ –í—Å–µ input_schema –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã")
    
    # –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ö–µ–º—ã
    if report['missing_schemas']:
        print(f"\n‚ùå –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï INPUT_SCHEMA:")
        for missing in report['missing_schemas']:
            print(f"  - {missing}")
            model_key, mode_id = missing.split(':')
            print(f"    –ù–ï –•–í–ê–¢–ê–ï–¢ –î–ê–ù–ù–´–• –î–õ–Ø –ú–û–î–ï–õ–ò {model_key}:{mode_id}:")
            print(f"    - –£—Ç–æ—á–Ω–∏—Ç—å required input_schema")
            print(f"    - –£—Ç–æ—á–Ω–∏—Ç—å available modes")
            print(f"    - –£—Ç–æ—á–Ω–∏—Ç—å pricing")
    
    # –£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –º–æ–¥–µ–ª–∏
    if report['outdated_models']:
        print(f"\n‚ö†Ô∏è –£–°–¢–ê–†–ï–í–®–ò–ï –ú–û–î–ï–õ–ò (–µ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ, –Ω–æ –Ω–µ—Ç –≤ API):")
        for model in report['outdated_models']:
            print(f"  - {model}")
    
    # –ù–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
    if report['new_models']:
        print(f"\nüÜï –ù–û–í–´–ï –ú–û–î–ï–õ–ò –í API (–Ω–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ):")
        for model in report['new_models']:
            print(f"  - {model}")
            api_modes = report['api_modes'].get(model, [])
            if api_modes:
                print(f"    Modes: {', '.join(api_modes)}")
    
    print("\n" + "="*80)
    
    # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    total_issues = (
        len(report['missing_models']) +
        sum(len(modes) for modes in report['missing_modes'].values()) +
        len(report['schema_errors']) +
        len(report['missing_schemas'])
    )
    
    if total_issues == 0:
        print("‚úÖ –í–°–ï –ü–†–û–í–ï–†–ö–ò –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏–¥–µ–∞–ª—å–Ω–∞!")
        return 0
    else:
        print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {total_issues}")
        print("\n‚ùó –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:")
        
        for model_key in report['missing_models']:
            api_modes = report['api_modes'].get(model_key, [])
            print(f"\n  –ù–ï –•–í–ê–¢–ê–ï–¢ –î–ê–ù–ù–´–• –î–õ–Ø –ú–û–î–ï–õ–ò {model_key}:")
            print(f"    - –£—Ç–æ—á–Ω–∏—Ç—å required input_schema")
            print(f"    - –£—Ç–æ—á–Ω–∏—Ç—å available modes: {', '.join(api_modes) if api_modes else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}")
            print(f"    - –£—Ç–æ—á–Ω–∏—Ç—å pricing")
        
        for model_key, modes in report['missing_modes'].items():
            print(f"\n  –ù–ï –•–í–ê–¢–ê–ï–¢ MODES –î–õ–Ø –ú–û–î–ï–õ–ò {model_key}:")
            for mode in modes:
                print(f"    - {mode}")
        
        return 1


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏."""
    logger.info("üöÄ –ù–∞—á–∞–ª–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π KIE AI...")
    
    # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ API
    api_models = await fetch_all_models_from_api()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
    local_models = load_local_models()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é
    report = check_models_sync(api_models, local_models)
    
    # –í—ã–≤–æ–¥–∏–º –æ—Ç—á—ë—Ç
    exit_code = print_detailed_report(report)
    
    return exit_code


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
