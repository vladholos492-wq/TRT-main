#!/usr/bin/env python3
"""
Ð“Ð»ÑƒÐ±Ð¾ÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· KIE.ai Market Ð´Ð»Ñ Ð¸Ð´ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸.
Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð²ÑÐµÑ… 47 Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, Ð¸Ñ… modes, pricing, input_schema.
"""

import os
import sys
import asyncio
import json
from pathlib import Path
from typing import Dict, List, Any, Set, Optional
from dotenv import load_dotenv
from datetime import datetime

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð² Ð¿ÑƒÑ‚ÑŒ
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

load_dotenv()

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def fetch_all_models_deep() -> List[Dict[str, Any]]:
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¸Ð· KIE API Ñ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹."""
    try:
        from kie_client import get_client
        
        client = get_client()
        models = await client.list_models()
        
        if not models:
            logger.warning("âš ï¸ API Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ð¼Ð¾Ð´ÐµÐ»Ð¸")
            return []
        
        logger.info(f"âœ… ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ {len(models)} Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¸Ð· API")
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        detailed_models = []
        for model in models:
            model_id = model.get('id') or model.get('model_id') or model.get('name', '')
            if not model_id:
                continue
            
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸
            model_details = await client.get_model(model_id)
            if model_details:
                detailed_models.append({
                    **model,
                    **model_details
                })
            else:
                detailed_models.append(model)
        
        return detailed_models
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: {e}", exc_info=True)
        return []


def extract_model_metadata(api_model: Dict[str, Any]) -> Dict[str, Any]:
    """
    Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° API.
    
    Returns:
        Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    """
    model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
    
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ provider
    provider = determine_provider(model_id)
    
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ category
    category = determine_category_from_model(api_model)
    
    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ modes
    modes = extract_all_modes(api_model)
    
    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ pricing
    pricing_info = extract_pricing_info(api_model)
    
    return {
        "model_id": model_id,
        "title": api_model.get('title') or api_model.get('name') or model_id,
        "provider": provider,
        "description": api_model.get('description') or api_model.get('help') or '',
        "category": category,
        "modes": modes,
        "pricing_info": pricing_info
    }


def determine_provider(model_id: str) -> str:
    """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ provider Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ model_id."""
    model_id_lower = model_id.lower()
    
    provider_map = {
        'sora': 'openai',
        'kling': 'kling',
        'wan': 'wan',
        'seedream': 'bytedance',
        'bytedance': 'bytedance',
        'nano': 'google',
        'banana': 'google',
        'gemini': 'google',
        'veo': 'google',
        'flux': 'blackforest',
        'qwen': 'qwen',
        'elevenlabs': 'elevenlabs',
        'hailuo': 'hailuo',
        'topaz': 'topaz',
        'recraft': 'recraft',
        'ideogram': 'ideogram',
        'infinitalk': 'infinitalk',
        'suno': 'suno',
        'midjourney': 'midjourney',
        'runway': 'runway',
        'grok': 'xai',
        'z-image': 'tongyi',
        '4o': 'openai',
        'openai': 'openai'
    }
    
    for key, provider in provider_map.items():
        if key in model_id_lower:
            return provider
    
    return 'unknown'


def determine_category_from_model(api_model: Dict[str, Any]) -> str:
    """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸."""
    category = api_model.get('category', '').lower()
    model_id = (api_model.get('id') or api_model.get('model_id') or '').lower()
    
    if 'video' in category or 'video' in model_id:
        return 'Video'
    elif 'image' in category or 'image' in model_id or 'photo' in category:
        return 'Image'
    elif 'audio' in category or 'audio' in model_id or 'speech' in model_id or 'music' in model_id:
        return 'Audio'
    elif 'music' in category or 'suno' in model_id:
        return 'Music'
    elif 'edit' in model_id or 'upscale' in model_id or 'remove' in model_id or 'watermark' in model_id:
        return 'Tools'
    else:
        return 'Other'


def extract_all_modes(api_model: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    """
    Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð²ÑÐµ modes Ð¸Ð· Ð¼Ð¾Ð´ÐµÐ»Ð¸.
    KIE API Ð¼Ð¾Ð¶ÐµÑ‚ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°Ñ‚ÑŒ model_types Ð¸Ð»Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÑ‚ÑŒ Ð¿Ð¾ input_schema.
    """
    modes = {}
    
    model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ model_types
    model_types = api_model.get('model_types', [])
    if model_types:
        for model_type in model_types:
            type_id = model_type.get('id') or model_type.get('type_id') or model_type.get('name', '')
            if not type_id:
                continue
            
            generation_type = determine_generation_type(type_id, model_type.get('input_schema', {}))
            
            mode_data = {
                "api_model": model_id,  # Ð ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ API model string
                "generation_type": generation_type,
                "input_schema": normalize_input_schema(model_type.get('input_schema', {})),
                "pricing": extract_mode_pricing(model_type, api_model),
                "help": model_type.get('description') or model_type.get('help') or api_model.get('description', '')
            }
            
            modes[type_id] = mode_data
    else:
        # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ model_types, Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ mode Ð¿Ð¾ input_schema
        input_schema = api_model.get('input_schema') or api_model.get('inputSchema') or {}
        generation_type = determine_generation_type(model_id, input_schema)
        
        mode_data = {
            "api_model": model_id,
            "generation_type": generation_type,
            "input_schema": normalize_input_schema(input_schema),
            "pricing": extract_mode_pricing(api_model, api_model),
            "help": api_model.get('description') or api_model.get('help', '')
        }
        
        modes[generation_type] = mode_data
    
    return modes


def determine_generation_type(model_id: str, input_schema: Dict[str, Any]) -> str:
    """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ñ‚Ð¸Ð¿ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸."""
    model_id_lower = model_id.lower()
    properties = input_schema.get('properties', {})
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð¾ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    if 'text-to-video' in model_id_lower or 'text_to_video' in model_id_lower:
        return 'text_to_video'
    elif 'image-to-video' in model_id_lower or 'image_to_video' in model_id_lower:
        return 'image_to_video'
    elif 'video-to-video' in model_id_lower or 'video_to_video' in model_id_lower:
        return 'video_to_video'
    elif 'text-to-image' in model_id_lower or 'text_to_image' in model_id_lower:
        return 'text_to_image'
    elif 'image-to-image' in model_id_lower or 'image_to_image' in model_id_lower:
        return 'image_to_image'
    elif 'image-edit' in model_id_lower or 'image_edit' in model_id_lower or 'edit' in model_id_lower:
        return 'image_edit'
    elif 'upscale' in model_id_lower:
        return 'image_upscale'
    elif 'watermark' in model_id_lower or 'remove' in model_id_lower:
        return 'video_edit'
    elif 'speech-to-video' in model_id_lower:
        return 'speech_to_video'
    elif 'text-to-speech' in model_id_lower:
        return 'text_to_speech'
    elif 'speech-to-text' in model_id_lower:
        return 'speech_to_text'
    elif 'text-to-music' in model_id_lower or 'music' in model_id_lower:
        return 'music_generation'
    elif 'audio' in model_id_lower:
        return 'audio_to_audio'
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð¾ input_schema
    if 'video_url' in properties:
        return 'video_to_video'
    elif 'image_urls' in properties or 'image_input' in properties or 'image_url' in properties:
        if 'prompt' in properties:
            if 'duration' in properties or 'n_frames' in properties:
                return 'image_to_video'
            else:
                return 'image_to_image'
        else:
            return 'image_upscale'
    elif 'prompt' in properties or 'text' in properties:
        if 'duration' in properties or 'n_frames' in properties:
            return 'text_to_video'
        else:
            return 'text_to_image'
    elif 'audio_url' in properties:
        return 'speech_to_text'
    
    return 'unknown'


def normalize_input_schema(schema: Dict[str, Any]) -> Dict[str, Any]:
    """ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÑ‚ input_schema Ðº ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ð¼Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ."""
    if not schema:
        return {"type": "object", "properties": {}, "required": []}
    
    # Ð•ÑÐ»Ð¸ ÑƒÐ¶Ðµ Ð² Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ
    if 'type' in schema and schema.get('type') == 'object':
        return schema
    
    # Ð•ÑÐ»Ð¸ ÑÑ‚Ð°Ñ€Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ (input_params)
    if 'input_params' in schema:
        properties = {}
        required = []
        
        for param_name, param_data in schema['input_params'].items():
            prop = {
                "type": param_data.get('type', 'string'),
                "description": param_data.get('description', '')
            }
            
            if 'enum' in param_data:
                prop['enum'] = param_data['enum']
            if 'default' in param_data:
                prop['default'] = param_data['default']
            if 'max_length' in param_data:
                prop['maxLength'] = param_data['max_length']
            if 'min' in param_data:
                prop['minimum'] = param_data['min']
            if 'max' in param_data:
                prop['maximum'] = param_data['max']
            if 'min_items' in param_data:
                prop['minItems'] = param_data['min_items']
            if 'max_items' in param_data:
                prop['maxItems'] = param_data['max_items']
            
            properties[param_name] = prop
            
            if param_data.get('required', False):
                required.append(param_name)
        
        return {
            "type": "object",
            "properties": properties,
            "required": required
        }
    
    return schema


def extract_pricing_info(api_model: Dict[str, Any]) -> Dict[str, Any]:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ†ÐµÐ½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¸."""
    pricing = api_model.get('pricing') or api_model.get('pricing_info') or {}
    
    # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ credits Ð¸Ð· Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¾Ð²
    credits = pricing.get('credits') or pricing.get('credit') or api_model.get('credits', 0)
    
    return {
        "credits": float(credits) if credits else 0.0,
        "description": pricing.get('description') or api_model.get('pricing', ''),
        "billing_rules": pricing.get('billing_rules') or {}
    }


def extract_mode_pricing(mode_data: Dict[str, Any], model_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ pricing Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ mode."""
    pricing = mode_data.get('pricing') or model_data.get('pricing') or {}
    
    credits = pricing.get('credits') or pricing.get('credit') or 0.0
    
    return {
        "credits": float(credits) if credits else 0.0,
        "credit_to_rub_rate": 0.1,  # ÐÐ´Ð¼Ð¸Ð½ÑÐºÐ¸Ð¹ ÐºÑƒÑ€Ñ (Ð½Ð°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÑ‚ÑÑ)
        "markup": 2.0  # ÐœÐ°Ñ€Ð¶Ð° x2
    }


async def analyze_all_models() -> Dict[str, Any]:
    """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð²ÑÐµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ."""
    logger.info("ðŸ” ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° KIE.ai Market...")
    
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸Ð· API
    api_models = await fetch_all_models_deep()
    
    if not api_models:
        logger.warning("âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸Ð· API, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ")
        try:
            from kie_models_new import KIE_MODELS
            # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
            analyzed = {}
            for model_key, model_data in KIE_MODELS.items():
                analyzed[model_key] = extract_model_metadata_from_local(model_key, model_data)
            return {"models": analyzed, "source": "local"}
        except ImportError:
            return {"models": {}, "source": "none", "error": "No models available"}
    
    # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ°Ð¶Ð´ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    analyzed_models = {}
    for api_model in api_models:
        metadata = extract_model_metadata(api_model)
        model_id = metadata["model_id"]
        analyzed_models[model_id] = metadata
    
    return {
        "models": analyzed_models,
        "source": "api",
        "total": len(analyzed_models)
    }


def extract_model_metadata_from_local(model_key: str, model_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹."""
    modes = {}
    for mode_id, mode_data_item in model_data.get("modes", {}).items():
        modes[mode_id] = {
            "api_model": mode_data_item.get("model", model_key),
            "generation_type": mode_data_item.get("generation_type", mode_id),
            "input_schema": mode_data_item.get("input_schema", {}),
            "pricing": {
                "credits": 0.0,
                "credit_to_rub_rate": 0.1,
                "markup": 2.0
            },
            "help": mode_data_item.get("help", "")
        }
    
    return {
        "model_id": model_key,
        "title": model_data.get("title", model_key),
        "provider": model_data.get("provider", "unknown"),
        "description": model_data.get("description", ""),
        "category": list(model_data.get("modes", {}).values())[0].get("category", "Other") if model_data.get("modes") else "Other",
        "modes": modes,
        "pricing_info": {
            "credits": 0.0,
            "description": "",
            "billing_rules": {}
        }
    }


def generate_master_catalogue(analyzed_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ master catalogue Ð² ÐµÐ´Ð¸Ð½Ð¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ðµ."""
    catalogue = {}
    
    for model_id, metadata in analyzed_data.get("models", {}).items():
        catalogue[model_id] = {
            "model_id": model_id,
            "title": metadata.get("title", model_id),
            "provider": metadata.get("provider", "unknown"),
            "description": metadata.get("description", ""),
            "category": metadata.get("category", "Other"),
            "modes": {}
        }
        
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ modes
        for mode_key, mode_data in metadata.get("modes", {}).items():
            catalogue[model_id]["modes"][mode_key] = {
                "api_model": mode_data.get("api_model", model_id),
                "generation_type": mode_data.get("generation_type", mode_key),
                "input_schema": mode_data.get("input_schema", {}),
                "pricing": mode_data.get("pricing", {
                    "credits": 0.0,
                    "credit_to_rub_rate": 0.1,
                    "markup": 2.0
                }),
                "help": mode_data.get("help", "")
            }
    
    return catalogue


def save_master_catalogue(catalogue: Dict[str, Any], filename: str = "master_catalogue.json"):
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ master catalogue Ð² Ñ„Ð°Ð¹Ð»."""
    filepath = root_dir / filename
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(catalogue, f, ensure_ascii=False, indent=2)
    
    logger.info(f"âœ… Master catalogue ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½ Ð² {filepath}")


def generate_analysis_report(analyzed_data: Dict[str, Any], catalogue: Dict[str, Any]) -> Dict[str, Any]:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°."""
    total_models = len(catalogue)
    total_modes = sum(len(m.get("modes", {})) for m in catalogue.values())
    
    missing_schemas = []
    invalid_schemas = []
    
    for model_id, model_data in catalogue.items():
        for mode_key, mode_data_item in model_data.get("modes", {}).items():
            input_schema = mode_data_item.get("input_schema", {})
            
            if not input_schema:
                missing_schemas.append(f"{model_id}:{mode_key}")
            elif not isinstance(input_schema, dict):
                invalid_schemas.append(f"{model_id}:{mode_key} - Ð½Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ")
            elif "properties" not in input_schema:
                invalid_schemas.append(f"{model_id}:{mode_key} - Ð½ÐµÑ‚ properties")
    
    return {
        "total_models_found": total_models,
        "total_modes_processed": total_modes,
        "missing_models": [],
        "missing_modes": {},
        "missing_input_schemas": missing_schemas,
        "invalid_input_schemas": invalid_schemas,
        "pricing_issues": [],
        "test_results": "PENDING",
        "api_errors": []
    }


async def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°."""
    logger.info("ðŸš€ ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° KIE.ai Market...")
    
    # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    analyzed_data = await analyze_all_models()
    
    # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ master catalogue
    catalogue = generate_master_catalogue(analyzed_data)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ catalogue
    save_master_catalogue(catalogue)
    
    # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚
    report = generate_analysis_report(analyzed_data, catalogue)
    
    # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚
    print("\n" + "="*80)
    print("ðŸ“Š ÐžÐ¢Ð§ÐÐ¢ Ð“Ð›Ð£Ð‘ÐžÐšÐžÐ“Ðž ÐÐÐÐ›Ð˜Ð—Ð KIE.AI MARKET")
    print("="*80)
    
    print(f"\nðŸ“‹ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ:")
    print(f"  Total models found: {report['total_models_found']}")
    print(f"  Total modes processed: {report['total_modes_processed']}")
    print(f"  Source: {analyzed_data.get('source', 'unknown')}")
    
    if report['missing_input_schemas']:
        print(f"\nâŒ ÐžÐ¢Ð¡Ð£Ð¢Ð¡Ð¢Ð’Ð£Ð®Ð©Ð˜Ð• INPUT_SCHEMA ({len(report['missing_input_schemas'])}):")
        for missing in report['missing_input_schemas'][:20]:
            print(f"  - {missing}")
        if len(report['missing_input_schemas']) > 20:
            print(f"  ... Ð¸ ÐµÑ‰Ðµ {len(report['missing_input_schemas']) - 20}")
    
    if report['invalid_input_schemas']:
        print(f"\nâš ï¸ ÐÐ•ÐšÐžÐ Ð Ð•ÐšÐ¢ÐÐ«Ð• INPUT_SCHEMA ({len(report['invalid_input_schemas'])}):")
        for invalid in report['invalid_input_schemas'][:20]:
            print(f"  - {invalid}")
        if len(report['invalid_input_schemas']) > 20:
            print(f"  ... Ð¸ ÐµÑ‰Ðµ {len(report['invalid_input_schemas']) - 20}")
    
    print("\n" + "="*80)
    
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

