#!/usr/bin/env python3
"""
üèóÔ∏è –ú–ê–°–¢–ï–†-–ü–ê–†–°–ï–† Kie.ai Copy Page

–ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –ò–°–¢–û–ß–ù–ò–ö –ò–°–¢–ò–ù–´ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏.
–ü–∞—Ä—Å–∏—Ç –û–î–ò–ù –†–ê–ó –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞–≤—Å–µ–≥–¥–∞.

–ò–∑–≤–ª–µ–∫–∞–µ—Ç:
- endpoint (—Ä–µ–∞–ª—å–Ω—ã–π API path)
- input_schema (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ Copy page)
- examples (–ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
- pricing (credits/gen –∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã)

–ê–≤—Ç–æ—Ä: AUTOPILOT
–î–∞—Ç–∞: 2025-12-24
"""

import json
import re
import time
from pathlib import Path
from typing import Dict, List, Optional, Any
from urllib.parse import urljoin
import requests
from bs4 import BeautifulSoup


class KieMasterParser:
    """–ú–∞—Å—Ç–µ—Ä-–ø–∞—Ä—Å–µ—Ä –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π Kie.ai"""
    
    BASE_URL = "https://docs.kie.ai"
    CACHE_DIR = Path("cache/kie_model_pages")
    OUTPUT_FILE = Path("models/KIE_PARSED_SOURCE_OF_TRUTH.json")
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.CACHE_DIR.mkdir(parents=True, exist_ok=True)
        
        # Load existing registry
        registry_path = Path("models/KIE_SOURCE_OF_TRUTH.json")
        with open(registry_path) as f:
            self.registry = json.load(f)
        
        # Load existing pricing (fallback)
        pricing_path = Path("artifacts/pricing_corrected_final.json")
        if pricing_path.exists():
            with open(pricing_path) as f:
                self.existing_pricing = json.load(f)
        else:
            self.existing_pricing = {}
    
    def get_model_doc_url(self, model_id: str) -> Optional[str]:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å URL –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        
        # –ú–∞–ø–ø–∏–Ω–≥ model_id -> doc path
        # –ü—Ä–∏–º–µ—Ä—ã –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã kie.ai/docs:
        # - qwen/z-image -> /market/z-image/z-image
        # - google/imagen4-fast -> /market/google/imagen4-fast
        # - sora-2-text-to-video -> /market/sora2/sora-2-text-to-video
        
        # Special single-name models
        if model_id == 'z-image':
            return f"{self.BASE_URL}/market/z-image/z-image"
        elif model_id == 'nano-banana-pro':
            return f"{self.BASE_URL}/market/google/nano-banana"
        
        if '/' in model_id:
            vendor, name = model_id.split('/', 1)
            
            # Special cases
            if vendor == 'qwen':
                return f"{self.BASE_URL}/market/z-image/{name}"
            
            elif vendor == 'google':
                return f"{self.BASE_URL}/market/google/{name}"
            
            elif vendor == 'flux-2':
                return f"{self.BASE_URL}/market/flux2/{name}"
            
            elif vendor == 'bytedance':
                if 'seedream' in name:
                    return f"{self.BASE_URL}/market/seedream/{name}"
                else:
                    return f"{self.BASE_URL}/market/bytedance/{name}"
            
            elif vendor == 'elevenlabs':
                return f"{self.BASE_URL}/market/elevenlabs/{name}"
            
            elif vendor == 'recraft':
                return f"{self.BASE_URL}/market/recraft/{name}"
            
            elif vendor == 'wan':
                return f"{self.BASE_URL}/market/wan/{name}"
            
            elif vendor == 'hailuo':
                return f"{self.BASE_URL}/market/hailuo/{name}"
            
            elif vendor == 'topaz':
                return f"{self.BASE_URL}/market/topaz/{name}"
            
            elif vendor == 'infinitalk':
                return f"{self.BASE_URL}/market/infinitalk/{name}"
            
            else:
                return f"{self.BASE_URL}/market/{vendor}/{name}"
        
        else:
            # –ú–æ–¥–µ–ª–∏ –±–µ–∑ vendor (sora-*, veo3_fast, V4)
            if model_id.startswith('sora-2'):
                return f"{self.BASE_URL}/market/sora2/{model_id}"
            elif model_id.startswith('sora-'):
                return f"{self.BASE_URL}/market/sora2/{model_id}"
            elif model_id.startswith('veo'):
                # veo3_fast, veo3.1
                return f"{self.BASE_URL}/veo3-api/quickstart"
            elif model_id == 'V4':
                # Seedream V4
                return f"{self.BASE_URL}/market/seedream/seedream"
            else:
                return None
    
    def fetch_page(self, url: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)"""
        
        # Cache key from URL
        cache_key = url.replace('https://', '').replace('/', '_') + '.html'
        cache_file = self.CACHE_DIR / cache_key
        
        # Check cache
        if cache_file.exists():
            print(f"   üì¶ Cache hit: {cache_key}")
            return cache_file.read_text(encoding='utf-8')
        
        # Fetch
        print(f"   üåê Fetching: {url}")
        try:
            resp = self.session.get(url, timeout=15)
            resp.raise_for_status()
            
            html = resp.text
            
            # Save to cache
            cache_file.write_text(html, encoding='utf-8')
            
            time.sleep(1)  # Be nice
            return html
            
        except Exception as e:
            print(f"   ‚ùå Error fetching {url}: {e}")
            return None
    
    def extract_from_copy_page(self, html: str, model_id: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Copy page (JSON –≤ —Å–∫—Ä–∏–ø—Ç–µ)"""
        
        result = {
            'endpoint': None,
            'input_schema': {},
            'examples': [],
            'pricing': {},
            '_metadata': {
                'source': 'copy_page',
                'parsed_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                'parser_version': '2.1.0'
            }
        }
        
        soup = BeautifulSoup(html, 'html.parser')
        
        # 1. –ü–æ–∏—Å–∫ endpoint –≤ JSON data (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç #1)
        # –ò—â–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: {"openapi":"path/to/model.json post /api/v1/jobs/createTask"}
        openapi_pattern = r'"openapi":\s*"[^"]*?(?:post|POST|get|GET)\s+(/api/v[0-9]+/[a-zA-Z]+(?:/[a-zA-Z]+)*)'
        openapi_match = re.search(openapi_pattern, html, re.I)
        if openapi_match:
            endpoint_raw = openapi_match.group(1)
            # Debug
            if model_id == 'z-image':
                print(f"   DEBUG: Raw match: {repr(endpoint_raw)}")
            result['endpoint'] = endpoint_raw
            result['_metadata']['endpoint_source'] = 'openapi_json'
        
        # 2. –ü–æ–∏—Å–∫ –≤ <script> —Ç–µ–≥–∞—Ö (Next.js –¥–∞–Ω–Ω—ã–µ)
        for script in soup.find_all('script'):
            if script.string and 'props' in script.string:
                # Try to extract JSON
                try:
                    # Look for endpoint patterns
                    if '/api/v1/' in script.string:
                        # Extract endpoint
                        endpoint_match = re.search(r'(/api/v1/[^"\']+)', script.string)
                        if endpoint_match:
                            result['endpoint'] = endpoint_match.group(1)
                    
                    # Look for pricing
                    credit_match = re.search(r'(\d+\.?\d*)\s*credits?\s*per', script.string, re.I)
                    if credit_match:
                        credits = float(credit_match.group(1))
                        result['pricing']['credits_per_gen'] = credits
                        result['pricing']['usd_per_gen'] = credits * 0.005  # 1 credit = $0.005
                    
                except:
                    pass
        
        # 2. –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        text = soup.get_text()
        
        # Pricing patterns
        for pattern in [
            r'(\d+\.?\d*)\s*credits?\s*per\s*(?:generation|call|video|image)',
            r'\$(\d+\.?\d*)\s*per\s*(?:generation|call|video|image)',
            r'(\d+\.?\d*)\s*kie\s*credits?'
        ]:
            match = re.search(pattern, text, re.I)
            if match:
                value = float(match.group(1))
                if '$' in pattern:
                    result['pricing']['usd_per_gen'] = value
                else:
                    result['pricing']['credits_per_gen'] = value
                    result['pricing']['usd_per_gen'] = value * 0.005
                break
        
        # 3. Extract code examples
        code_blocks = soup.find_all('code')
        for block in code_blocks:
            code = block.get_text()
            if 'prompt' in code or 'imageUrl' in code:
                if len(code) > 50:  # Meaningful example
                    result['examples'].append(code[:500])
        
        return result
    
    def parse_model(self, model_id: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç—å –û–î–ù–£ –º–æ–¥–µ–ª—å –ø–æ–ª–Ω–æ—Å—Ç—å—é"""
        
        print(f"\nüîç Parsing: {model_id}")
        
        # Get doc URL
        url = self.get_model_doc_url(model_id)
        if not url:
            print(f"   ‚ö†Ô∏è  No doc URL mapping for {model_id}")
            return {}
        
        # Fetch page
        html = self.fetch_page(url)
        if not html:
            return {}
        
        # Extract
        data = self.extract_from_copy_page(html, model_id)
        
        # Fallback pricing from existing data
        if not data.get('pricing') or not data['pricing'].get('usd_per_gen'):
            if model_id in self.existing_pricing:
                existing = self.existing_pricing[model_id]
                data['pricing'] = {
                    'usd_per_gen': existing.get('usd_per_gen'),
                    'rub_per_gen': existing.get('rub_per_gen'),
                    'credits_per_gen': existing.get('credits_per_gen'),
                    'source': 'pricing_table_corrected'
                }
                data['_metadata']['pricing_source'] = 'pricing_table_fallback'
                print(f"   üíæ Pricing (fallback): ${existing.get('usd_per_gen', 0):.3f}")
        
        print(f"   ‚úÖ Endpoint: {data.get('endpoint', 'N/A')}")
        print(f"   ‚úÖ Pricing: {data.get('pricing', {})}")
        print(f"   ‚úÖ Examples: {len(data.get('examples', []))}")
        
        return data
    
    def parse_all_models(self, limit: Optional[int] = None):
        """–ü–∞—Ä—Å–∏—Ç—å –í–°–ï –º–æ–¥–µ–ª–∏ –∏–∑ registry"""
        
        print("üèóÔ∏è  –ú–ê–°–¢–ï–†-–ü–ê–†–°–ï–†: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ SOURCE OF TRUTH –∏–∑ Kie.ai\n")
        print("=" * 70)
        
        models = self.registry['models']
        model_ids = list(models.keys())
        
        if limit:
            model_ids = model_ids[:limit]
        
        parsed_data = {}
        
        for i, model_id in enumerate(model_ids, 1):
            print(f"\n[{i}/{len(model_ids)}]", end=' ')
            
            data = self.parse_model(model_id)
            if data:
                parsed_data[model_id] = data
        
        # Save
        print(f"\n\nüíæ Saving to {self.OUTPUT_FILE}")
        
        output = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_models': len(model_ids),
            'parsed_successfully': len(parsed_data),
            'models': parsed_data
        }
        
        self.OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(self.OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Saved {len(parsed_data)}/{len(model_ids)} models")
        print(f"\nüìä Coverage: {len(parsed_data)/len(model_ids)*100:.1f}%")
        
        return parsed_data


def main():
    """Main entry point"""
    
    import sys
    
    parser = KieMasterParser()
    
    # Parse all or specific model
    if len(sys.argv) > 1:
        if sys.argv[1] == '--all':
            # Parse ALL models (no limit)
            parser.parse_all_models(limit=None)
        else:
            model_id = sys.argv[1]
            parser.parse_model(model_id)
    else:
        # Default: parse ALL models
        print("‚ö†Ô∏è  No arguments - parsing ALL 72 models!")
        print("   Use: python master_kie_parser.py <model_id> for single model")
        print("   Use: python master_kie_parser.py --all for explicit all\n")
        parser.parse_all_models(limit=None)


if __name__ == '__main__':
    main()
