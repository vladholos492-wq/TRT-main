#!/usr/bin/env python3
"""
Render Logs Check - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ Render –Ω–∞ –æ—à–∏–±–∫–∏.

–ß–∏—Ç–∞–µ—Ç Desktop/TRT_RENDER.env –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –º–∏–Ω—É—Ç –ª–æ–≥–æ–≤ —á–µ—Ä–µ–∑ Render API.
"""

import sys
import os
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import re

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def load_render_config() -> Dict[str, str]:
    """
    Load Render config from Desktop/TRT_RENDER.env.
    
    Returns:
        Dict with RENDER_API_KEY, RENDER_SERVICE_ID, DATABASE_URL_READONLY
    """
    # Detect Desktop path
    if os.name == 'nt':  # Windows
        desktop_path = Path(os.getenv('USERPROFILE', '')) / 'Desktop'
    else:  # macOS/Linux
        desktop_path = Path.home() / 'Desktop'
    
    env_file = desktop_path / 'TRT_RENDER.env'
    
    if not env_file.exists():
        print(f"‚ö†Ô∏è  Config file not found: {env_file}")
        print("   Create it with:")
        print("   RENDER_API_KEY=your_key")
        print("   RENDER_SERVICE_ID=your_service_id")
        print("   DATABASE_URL_READONLY=your_readonly_url")
        return {}
    
    config = {}
    with open(env_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            if '=' in line:
                key, value = line.split('=', 1)
                config[key.strip()] = value.strip()
    
    return config


def redact_secret(value: str, show_chars: int = 4) -> str:
    """Redact secret, showing only last N chars."""
    if not value or len(value) <= show_chars:
        return "****"
    return "*" * (len(value) - show_chars) + value[-show_chars:]


def redact_secrets_in_log_line(line: str) -> str:
    """
    Redact secrets in a log line (tokens, passwords, API keys, etc.).
    
    Patterns to redact:
    - Bearer tokens: Bearer <token>
    - API keys: api_key=<value>, API_KEY=<value>
    - Passwords: password=<value>, pwd=<value>
    - Tokens: token=<value>, TOKEN=<value>
    - Database URLs: postgresql://, postgres:// (keep hostname, redact credentials)
    - Telegram tokens: TELEGRAM_BOT_TOKEN=<value>
    """
    import re
    
    # Redact Bearer tokens
    line = re.sub(r'Bearer\s+([A-Za-z0-9_-]{20,})', r'Bearer ***REDACTED***', line)
    
    # Redact API keys and tokens in KEY=VALUE format
    line = re.sub(
        r'((?:api[_-]?key|API[_-]?KEY|token|TOKEN|password|PASSWORD|pwd|PWD|secret|SECRET)\s*[=:]\s*)([A-Za-z0-9_-]{10,})',
        r'\1***REDACTED***',
        line,
        flags=re.IGNORECASE
    )
    
    # Redact database URLs (keep protocol and hostname, redact credentials and full URL)
    # Match: postgresql://user:pass@host:port/db or postgres://user:pass@host:port/db
    line = re.sub(
        r'(postgresql?://)([^:]+):([^@]+)@([^/\s]+)(/[^\s]*)?',
        r'\1***USER***:***PASSWORD***@\4***DB***',
        line,
        flags=re.IGNORECASE
    )
    
    # Also redact DATABASE_URL=... patterns (full URL redaction)
    line = re.sub(
        r'(DATABASE_URL\s*[=:]\s*)(postgresql?://[^\s]+)',
        r'\1***REDACTED***',
        line,
        flags=re.IGNORECASE
    )
    
    # Redact long hex strings (likely tokens)
    line = re.sub(r'\b([A-Fa-f0-9]{32,})\b', lambda m: '*' * min(len(m.group(1)), 20) + '...' if len(m.group(1)) > 20 else '***REDACTED***', line)
    
    return line


def fetch_render_logs(api_key: str, service_id: str, minutes: int = 30) -> List[str]:
    """
    Fetch logs from Render API for last N minutes.
    
    Returns:
        List of log lines
    """
    try:
        import aiohttp
        import asyncio
    except ImportError:
        print("‚ö†Ô∏è  aiohttp not available, using requests fallback")
        try:
            import requests
        except ImportError:
            print("‚ùå Neither aiohttp nor requests available")
            return []
    
    # Render API endpoint
    url = f"https://api.render.com/v1/services/{service_id}/logs"
    
    # Calculate timestamp (last N minutes)
    since = datetime.utcnow() - timedelta(minutes=minutes)
    since_iso = since.isoformat() + 'Z'
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Accept": "application/json"
    }
    
    params = {
        "since": since_iso,
        "limit": 1000  # Max lines
    }
    
    try:
        # Try aiohttp first (async)
        import asyncio
        import aiohttp
        
        async def fetch():
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params, timeout=aiohttp.ClientTimeout(total=15)) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        # Render API returns logs in different formats, extract lines
                        logs = data.get("logs", [])
                        if isinstance(logs, list):
                            return [log.get("message", str(log)) for log in logs]
                        elif isinstance(logs, str):
                            return logs.split('\n')
                        return []
                    else:
                        print(f"‚ö†Ô∏è  Render API returned {resp.status}: {await resp.text()}")
                        return []
        
        return asyncio.run(fetch())
        
    except Exception as e:
        # Fallback to requests (sync)
        try:
            import requests
            resp = requests.get(url, headers=headers, params=params, timeout=15)
            if resp.status_code == 200:
                data = resp.json()
                logs = data.get("logs", [])
                if isinstance(logs, list):
                    return [log.get("message", str(log)) for log in logs]
                elif isinstance(logs, str):
                    return logs.split('\n')
                return []
            else:
                print(f"‚ö†Ô∏è  Render API returned {resp.status_code}: {resp.text[:200]}")
                return []
        except Exception as e2:
            print(f"‚ùå Failed to fetch logs: {e2}")
            return []


def analyze_logs(logs: List[str], redact_secrets: bool = True) -> Dict[str, Any]:
    """
    Analyze logs for errors, exceptions, and critical issues.

    Args:
        logs: List of log lines
        redact_secrets: If True, redact secrets in log lines before analysis

    Returns:
        Dict with counts and top errors (with redacted secrets)
    """
    errors = []
    exceptions = []
    import_errors = []
    tracebacks = []
    warnings = []
    info_lines = []
    startup_lines = []
    boot_fails = []
    dispatch_fails = []
    active_passive_states = []
    versions = []
    callback_data_list = []

    # Patterns to detect
    error_pattern = re.compile(r'(?i)(error|failed|failure|exception|traceback|import.*error)')
    traceback_pattern = re.compile(r'(?i)(traceback|file ".*", line \d+)')
    import_error_pattern = re.compile(r'(?i)(import.*error|cannot import)')
    warning_pattern = re.compile(r'(?i)(warning|warn)')
    info_pattern = re.compile(r'(?i)(info|‚úÖ|‚ÑπÔ∏è)')
    startup_pattern = re.compile(r'(?i)(startup|boot|self-check|initialization|deploy_topology|startup_summary)')
    
    # New patterns for enhanced analysis
    boot_fail_pattern = re.compile(r'(?i)(boot_fail|boot.*fail|boot.*failed)')
    dispatch_fail_pattern = re.compile(r'(?i)(dispatch_fail|dispatch.*fail)')
    active_passive_pattern = re.compile(r'(?i)(is_active_state=(ACTIVE|PASSIVE)|lock_state=(ACTIVE|PASSIVE))')
    version_pattern = re.compile(r'(?i)(commit_sha=([a-f0-9]{7})|version=([a-f0-9]{7})|git_sha=([a-f0-9]{7}))')
    callback_data_pattern = re.compile(r'(?i)(callback_data=[\'"]?([^\s\'"]+)[\'"]?|data=[\'"]?([^\s\'"]+)[\'"]?)')

    for i, line in enumerate(logs):
        # Redact secrets if requested
        if redact_secrets:
            line = redact_secrets_in_log_line(line)
        
        if error_pattern.search(line):
            errors.append((i, line))
        if traceback_pattern.search(line):
            tracebacks.append((i, line))
        if import_error_pattern.search(line):
            import_errors.append((i, line))
        if warning_pattern.search(line) and not error_pattern.search(line):
            warnings.append((i, line))
        if info_pattern.search(line) and not error_pattern.search(line):
            info_lines.append((i, line))
        if startup_pattern.search(line):
            startup_lines.append((i, line))
        
        # Enhanced analysis patterns
        if boot_fail_pattern.search(line):
            boot_fails.append((i, line))
        if dispatch_fail_pattern.search(line):
            dispatch_fails.append((i, line))
        
        # Extract ACTIVE/PASSIVE state
        active_passive_match = active_passive_pattern.search(line)
        if active_passive_match:
            state = active_passive_match.group(1) or active_passive_match.group(2)
            active_passive_states.append((i, state, line))
        
        # Extract version/commit SHA
        version_match = version_pattern.search(line)
        if version_match:
            sha = version_match.group(2) or version_match.group(3) or version_match.group(4)
            if sha:
                versions.append(sha)
        
        # Extract callback_data
        callback_match = callback_data_pattern.search(line)
        if callback_match:
            data = callback_match.group(2) or callback_match.group(3)
            if data and data not in ["'", '"', "="]:
                callback_data_list.append(data)

    # Extract exception types
    exception_types = {}
    for _, line in errors:
        # Try to extract exception type (e.g., "ImportError:", "TypeError:")
        match = re.search(r'(\w+Error|\w+Exception):', line)
        if match:
            exc_type = match.group(1)
            exception_types[exc_type] = exception_types.get(exc_type, 0) + 1
    
    # Extract DISPATCH_FAIL by handler
    dispatch_fail_by_handler = {}
    for _, line in dispatch_fails:
        # Try to extract handler name from DISPATCH_FAIL logs
        handler_match = re.search(r'Handler=([^\s]+)', line)
        if handler_match:
            handler = handler_match.group(1)
            dispatch_fail_by_handler[handler] = dispatch_fail_by_handler.get(handler, 0) + 1
    
    # Get latest version (most recent commit SHA)
    latest_version = versions[-1] if versions else "unknown"
    
    # Get latest ACTIVE/PASSIVE state
    latest_state = active_passive_states[-1][1] if active_passive_states else "unknown"
    
    # Top callback_data (what users clicked)
    from collections import Counter
    top_callbacks = Counter(callback_data_list).most_common(5)
    
    # Top 3 reasons for failures (from error messages)
    failure_reasons = []
    for _, line in errors[:20]:  # Check top 20 errors
        # Try to extract reason/error message
        reason_match = re.search(r'(?i)(reason=|message=|error[:\s]+)([^,\n]{0,50})', line)
        if reason_match:
            reason = reason_match.group(2).strip()
            if reason and len(reason) > 5:
                failure_reasons.append(reason)
    top_3_reasons = Counter(failure_reasons).most_common(3)

    return {
        "total_lines": len(logs),
        "error_count": len(errors),
        "exception_count": len(exceptions),
        "import_error_count": len(import_errors),
        "traceback_count": len(tracebacks),
        "warning_count": len(warnings),
        "info_count": len(info_lines),
        "startup_count": len(startup_lines),
        "boot_fail_count": len(boot_fails),
        "dispatch_fail_count": len(dispatch_fails),
        "top_errors": errors[:10],  # Top 10 errors
        "top_import_errors": import_errors[:5],
        "top_warnings": warnings[:5],
        "top_startup_lines": startup_lines[:5],
        "exception_types": exception_types,
        "latest_version": latest_version,
        "latest_state": latest_state,
        "dispatch_fail_by_handler": dispatch_fail_by_handler,
        "top_3_reasons": [reason for reason, _ in top_3_reasons],
        "top_callbacks": [callback for callback, _ in top_callbacks],
    }


def print_report(analysis: Dict[str, Any], minutes: int, redact_secrets: bool = True):
    """
    Print diagnostic report with summary.
    
    Args:
        analysis: Analysis results from analyze_logs()
        minutes: Number of minutes of logs checked
        redact_secrets: Whether secrets were redacted (for display)
    """
    print("\n" + "=" * 70)
    print(f"  RENDER LOGS CHECK - SUMMARY (last {minutes} minutes)")
    print("=" * 70)
    
    # Overall statistics
    print(f"\n  üìä STATISTICS:")
    print(f"     Total log lines: {analysis['total_lines']}")
    print(f"     Latest version: {analysis.get('latest_version', 'unknown')}")
    print(f"     Latest state: {analysis.get('latest_state', 'unknown')}")
    print(f"     Errors: {analysis['error_count']}")
    print(f"     Import Errors: {analysis['import_error_count']}")
    print(f"     Tracebacks: {analysis['traceback_count']}")
    print(f"     Warnings: {analysis['warning_count']}")
    print(f"     Info messages: {analysis.get('info_count', 0)}")
    print(f"     Startup events: {analysis.get('startup_count', 0)}")
    print(f"     BOOT_FAIL count: {analysis.get('boot_fail_count', 0)}")
    print(f"     DISPATCH_FAIL count: {analysis.get('dispatch_fail_count', 0)}")
    
    if redact_secrets:
        print(f"\n  üîí Secrets redacted in output")

    # Exception types breakdown
    if analysis['exception_types']:
        print(f"\n  üîç EXCEPTION TYPES:")
        for exc_type, count in sorted(analysis['exception_types'].items(), key=lambda x: -x[1]):
            print(f"     - {exc_type}: {count}")

    # Top import errors (critical)
    if analysis['top_import_errors']:
        print(f"\n  ‚ö†Ô∏è  TOP IMPORT ERRORS (CRITICAL):")
        for idx, (line_num, line) in enumerate(analysis['top_import_errors'], 1):
            # Truncate long lines, preserve context
            display_line = line[:120] + "..." if len(line) > 120 else line
            print(f"     {idx}. Line {line_num}: {display_line}")

    # Top errors
    if analysis['top_errors']:
        print(f"\n  ‚ö†Ô∏è  TOP ERRORS:")
        for idx, (line_num, line) in enumerate(analysis['top_errors'][:5], 1):
            display_line = line[:120] + "..." if len(line) > 120 else line
            print(f"     {idx}. Line {line_num}: {display_line}")

    # Top warnings
    if analysis.get('top_warnings'):
        print(f"\n  ‚ö†Ô∏è  TOP WARNINGS:")
        for idx, (line_num, line) in enumerate(analysis['top_warnings'][:3], 1):
            display_line = line[:120] + "..." if len(line) > 120 else line
            print(f"     {idx}. Line {line_num}: {display_line}")

    # Startup events (if any)
    if analysis.get('top_startup_lines'):
        print(f"\n  üöÄ STARTUP EVENTS:")
        for idx, (line_num, line) in enumerate(analysis['top_startup_lines'][:3], 1):
            display_line = line[:100] + "..." if len(line) > 100 else line
            print(f"     {idx}. Line {line_num}: {display_line}")
    
    # DISPATCH_FAIL by handler
    if analysis.get('dispatch_fail_by_handler'):
        print(f"\n  üîç DISPATCH_FAIL BY HANDLER:")
        for handler, count in sorted(analysis['dispatch_fail_by_handler'].items(), key=lambda x: -x[1]):
            print(f"     - {handler}: {count}")
    
    # Top 3 reasons
    if analysis.get('top_3_reasons'):
        print(f"\n  üîç TOP 3 FAILURE REASONS:")
        for idx, reason in enumerate(analysis['top_3_reasons'], 1):
            print(f"     {idx}. {reason[:80]}")
    
    # Top callbacks (what users clicked)
    if analysis.get('top_callbacks'):
        print(f"\n  üîò TOP CALLBACKS (what users clicked):")
        for idx, callback in enumerate(analysis['top_callbacks'], 1):
            print(f"     {idx}. {callback}")

    print("\n" + "=" * 70)
    
    # Final verdict
    if analysis['import_error_count'] > 0 or analysis['traceback_count'] > 0:
        print("  ‚ùå CRITICAL ISSUES FOUND")
        print("     Action: Review logs above and fix ImportError/Traceback issues")
        return 1
    elif analysis['error_count'] > 0:
        print("  ‚ö†Ô∏è  ERRORS FOUND (non-critical)")
        print("     Action: Review errors above, may need attention")
        return 0
    else:
        print("  ‚úÖ NO CRITICAL ERRORS")
        print("     Status: Logs look clean")
        return 0


def main():
    """Main function."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Check Render logs for errors")
    parser.add_argument("--minutes", type=int, default=30, help="Minutes of logs to check")
    parser.add_argument("--skip-network", action="store_true", help="Skip network calls (for testing)")
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("  RENDER LOGS CHECK")
    print("=" * 60)
    
    # Load config
    config = load_render_config()
    if not config:
        print("\n‚ùå Config not loaded, exiting")
        return 1
    
    api_key = config.get("RENDER_API_KEY")
    service_id = config.get("RENDER_SERVICE_ID")
    
    if not api_key or not service_id:
        print("\n‚ùå RENDER_API_KEY or RENDER_SERVICE_ID missing")
        return 1
    
    print(f"\n  API Key: {redact_secret(api_key)}")
    print(f"  Service ID: {service_id}")
    print(f"  Minutes: {args.minutes}")
    
    if args.skip_network:
        print("\n  ‚è≠Ô∏è  Skipping network (--skip-network)")
        return 0
    
    # Fetch logs
    print("\n  üì• Fetching logs...")
    logs = fetch_render_logs(api_key, service_id, args.minutes)
    
    if not logs:
        print("  ‚ö†Ô∏è  No logs fetched (API unavailable or empty)")
        return 0
    
    print(f"  ‚úÖ Fetched {len(logs)} log lines")
    
    # Analyze (with secret redaction)
    print("  üîç Analyzing logs (secrets will be redacted)...")
    analysis = analyze_logs(logs, redact_secrets=True)

    # Print report
    exit_code = print_report(analysis, args.minutes, redact_secrets=True)
    
    # Save sanitized logs to artifacts (optional)
    if logs:
        artifacts_dir = project_root / "artifacts"
        artifacts_dir.mkdir(exist_ok=True)
        
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        sanitized_file = artifacts_dir / f"render_logs_sanitized_{timestamp}.txt"
        
        # Write redacted logs
        with open(sanitized_file, 'w', encoding='utf-8') as f:
            for line in logs:
                redacted_line = redact_secrets_in_log_line(line)
                f.write(redacted_line + '\n')
        
        print(f"\n  üíæ Sanitized logs saved to: {sanitized_file}")

    return exit_code


if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"\n‚ùå Fatal error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

