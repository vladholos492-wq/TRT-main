#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π –∏–∑ KIE API —Å kie_models.py.
–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ API, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å —Ç–µ–∫—É—â–∏–º —Å–ø–∏—Å–∫–æ–º –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ.
"""

import asyncio
import sys
import os
import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
root_dir = Path(__file__).parent
sys.path.insert(0, str(root_dir))

from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def normalize_api_model_to_kie_format(api_model: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ API –∫ —Ñ–æ—Ä–º–∞—Ç—É kie_models.py.
    """
    model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
    if not model_id:
        return None
    
    title = api_model.get('title') or api_model.get('name') or model_id
    description = api_model.get('description') or api_model.get('help') or api_model.get('instructions', '')
    if not description:
        description = f"–ú–æ–¥–µ–ª—å {title} –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."
    
    category = api_model.get('category') or api_model.get('type') or 'Unknown'
    emoji = api_model.get('emoji') or '‚ú®'
    
    # –ü–æ–ª—É—á–∞–µ–º input_schema
    input_schema = api_model.get('input_schema') or api_model.get('input_params') or api_model.get('input') or {}
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º generation_type –Ω–∞ –æ—Å–Ω–æ–≤–µ model_id –∏ input_schema
    generation_type = api_model.get('generation_type') or api_model.get('type') or 'unknown'
    if generation_type == 'unknown':
        model_id_lower = model_id.lower()
        if 'text-to-image' in model_id_lower or 'text_to_image' in model_id_lower or 'texttoimage' in model_id_lower:
            generation_type = 'text-to-image'
        elif 'image-to-image' in model_id_lower or 'image_to_image' in model_id_lower or 'imagetoimage' in model_id_lower:
            generation_type = 'image-to-image'
        elif 'text-to-video' in model_id_lower or 'text_to_video' in model_id_lower or 'texttovideo' in model_id_lower:
            generation_type = 'text-to-video'
        elif 'image-to-video' in model_id_lower or 'image_to_video' in model_id_lower or 'imagetovideo' in model_id_lower:
            generation_type = 'image-to-video'
        elif 'edit' in model_id_lower:
            generation_type = 'image-edit'
        elif 'upscale' in model_id_lower:
            generation_type = 'image-upscale'
        elif 'video' in model_id_lower:
            generation_type = 'video-processing'
        elif 'audio' in model_id_lower or 'speech' in model_id_lower or 'sound' in model_id_lower:
            generation_type = 'audio-processing'
        else:
            generation_type = 'text-to-image'  # Default
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º pricing (–ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
    pricing = api_model.get('pricing') or "–¶–µ–Ω–∞ —É—Ç–æ—á–Ω—è–µ—Ç—Å—è"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º help —Ç–µ–∫—Å—Ç
    help_text = description
    if not help_text or help_text == f"–ú–æ–¥–µ–ª—å {title} –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.":
        if 'text-to-image' in generation_type:
            help_text = "–û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –≤—ã–±–µ—Ä–∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω –∏ –ø–æ–ª—É—á–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
        elif 'image-to-image' in generation_type:
            help_text = "–û—Ç–ø—Ä–∞–≤—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        elif 'text-to-video' in generation_type:
            help_text = "–û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –∏ –ø–æ–ª—É—á–∏ –≤–∏–¥–µ–æ."
        elif 'image-to-video' in generation_type:
            help_text = "–û—Ç–ø—Ä–∞–≤—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–∏ –≤–∏–¥–µ–æ."
        elif 'audio' in generation_type:
            help_text = "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤."
        else:
            help_text = f"–ò—Å–ø–æ–ª—å–∑—É–π –º–æ–¥–µ–ª—å {title} –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º example_prompt
    example_prompt = api_model.get('example_prompt') or api_model.get('example')
    if not example_prompt:
        if 'text-to-image' in generation_type or 'image-to-image' in generation_type:
            example_prompt = "–ö—Ä–∞—Å–∏–≤—ã–π –∑–∞–∫–∞—Ç –Ω–∞–¥ –æ–∫–µ–∞–Ω–æ–º —Å –ª–µ—Ç–∞—é—â–∏–º–∏ –ø—Ç–∏—Ü–∞–º–∏"
        elif 'text-to-video' in generation_type or 'image-to-video' in generation_type:
            example_prompt = "–°–ø–æ–∫–æ–π–Ω–æ–µ –≤–∏–¥–µ–æ —Å –≤–æ–ª–Ω–∞–º–∏ –Ω–∞ –ø–ª—è–∂–µ"
        elif 'audio' in generation_type:
            example_prompt = "–ü—Ä–∏–º–µ—Ä –∞—É–¥–∏–æ –∑–∞–ø—Ä–æ—Å–∞"
        else:
            example_prompt = "–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    normalized = {
        "id": model_id,
        "name": title,
        "description": description,
        "category": category,
        "emoji": emoji,
        "pricing": pricing,
        "input_params": input_schema,
        "generation_type": generation_type,
        "help": help_text,
        "example_prompt": example_prompt
    }
    
    return normalized


def format_model_for_kie_models_py(model: Dict[str, Any], indent: int = 1) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ kie_models.py.
    """
    indent_str = "    " * indent
    next_indent = "    " * (indent + 1)
    param_indent = "    " * (indent + 2)
    
    lines = [f"{indent_str}{{"]
    
    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
    lines.append(f'{next_indent}"id": "{model["id"]}",')
    lines.append(f'{next_indent}"name": "{model["name"]}",')
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫–∞–≤—ã—á–∫–∏ –≤ description
    desc = model["description"].replace('"', '\\"').replace('\n', '\\n')
    lines.append(f'{next_indent}"description": "{desc}",')
    lines.append(f'{next_indent}"category": "{model["category"]}",')
    lines.append(f'{next_indent}"emoji": "{model["emoji"]}",')
    pricing = model["pricing"].replace('"', '\\"')
    lines.append(f'{next_indent}"pricing": "{pricing}",')
    
    # input_params
    lines.append(f'{next_indent}"input_params": {{')
    input_params = model.get("input_params", {})
    if input_params:
        for param_name, param_info in input_params.items():
            if isinstance(param_info, dict):
                lines.append(f'{param_indent}"{param_name}": {{')
                for key, value in param_info.items():
                    if key == "enum" and isinstance(value, list):
                        enum_str = ", ".join([f'"{item}"' if isinstance(item, str) else str(item) for item in value])
                        lines.append(f'{param_indent}    "{key}": [{enum_str}],')
                    elif isinstance(value, str):
                        escaped = value.replace('"', '\\"').replace('\n', '\\n')
                        lines.append(f'{param_indent}    "{key}": "{escaped}",')
                    elif isinstance(value, bool):
                        lines.append(f'{param_indent}    "{key}": {str(value).lower()},')
                    elif isinstance(value, (int, float)):
                        lines.append(f'{param_indent}    "{key}": {value},')
                    elif isinstance(value, list):
                        items_str = ", ".join([f'"{item}"' if isinstance(item, str) else str(item) for item in value])
                        lines.append(f'{param_indent}    "{key}": [{items_str}],')
                    else:
                        lines.append(f'{param_indent}    "{key}": {json.dumps(value, ensure_ascii=False)},')
                # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø—è—Ç—É—é
                if lines[-1].endswith(','):
                    lines[-1] = lines[-1][:-1]
                lines.append(f'{param_indent}}},')
            else:
                lines.append(f'{param_indent}"{param_name}": {json.dumps(param_info, ensure_ascii=False)},')
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π prompt
        lines.append(f'{param_indent}"prompt": {{')
        lines.append(f'{param_indent}    "type": "string",')
        lines.append(f'{param_indent}    "description": "–¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏",')
        lines.append(f'{param_indent}    "required": True')
        lines.append(f'{param_indent}}}')
    
    lines.append(f'{next_indent}}}')
    lines.append(f"{indent_str}}},")
    
    return "\n".join(lines)


async def fetch_models_from_api() -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ KIE API."""
    try:
        from kie_client import get_client
        client = get_client()
        
        logger.info("üì° –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏–∑ KIE API...")
        models = await client.list_models()
        
        if not models:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ API. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            logger.warning("  - KIE_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            logger.warning("  - API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            logger.warning("  - –ù–µ–≤–µ—Ä–Ω—ã–π endpoint")
            return []
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –∏–∑ API")
        return models
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π –∏–∑ API: {e}", exc_info=True)
        return []


def get_current_models() -> Dict[str, Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ kie_models.py."""
    try:
        from kie_models import KIE_MODELS
        return {model['id']: model for model in KIE_MODELS}
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π –∏–∑ kie_models.py: {e}", exc_info=True)
        return {}


async def find_missing_models() -> List[Dict[str, Any]]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –º–æ–¥–µ–ª–∏ –∏–∑ API, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ kie_models.py.
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ API
    api_models = await fetch_models_from_api()
    
    if not api_models:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ API. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø—É—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º.")
        return []
    
    # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–¥–∞
    code_models = get_current_models()
    code_model_ids = set(code_models.keys())
    
    # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏
    missing_models = []
    for api_model in api_models:
        normalized = normalize_api_model_to_kie_format(api_model)
        if not normalized:
            continue
        
        model_id = normalized['id']
        
        if model_id and model_id not in code_model_ids:
            missing_models.append(normalized)
            logger.info(f"‚ûï –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å: {model_id} ({normalized['name']})")
    
    return missing_models


def add_models_to_kie_models_py(new_models: List[Dict[str, Any]], kie_models_file: Path) -> bool:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –≤ kie_models.py.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã.
    """
    if not new_models:
        return False
    
    # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª
    try:
        with open(kie_models_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {kie_models_file}: {e}")
        return False
    
    # –ù–∞—Ö–æ–¥–∏–º –º–µ—Å—Ç–æ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ (–ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–æ–π —Å–ø–∏—Å–∫–∞ KIE_MODELS)
    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å –≤ —Å–ø–∏—Å–∫–µ
    pattern = r'(\s+)\]\s*$'
    match = re.search(pattern, content, re.MULTILINE)
    
    if not match:
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø—Ä–æ—Å—Ç–æ ]
        pattern = r'\]\s*$'
        match = re.search(pattern, content, re.MULTILINE)
        if not match:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–µ—Å—Ç–æ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π")
            return False
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–¥ –¥–ª—è –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
    new_code_lines = []
    new_code_lines.append("\n    # –ù–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –∏–∑ KIE API")
    new_code_lines.append("    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å–∫—Ä–∏–ø—Ç–æ–º sync_models_from_api.py")
    new_code_lines.append("")
    
    for model in new_models:
        model_code = format_model_for_kie_models_py(model, indent=1)
        new_code_lines.append(model_code)
        new_code_lines.append("")
    
    new_code = "\n".join(new_code_lines)
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–æ–π
    insert_pos = match.start()
    new_content = content[:insert_pos] + new_code + "\n" + content[insert_pos:]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    try:
        # –°–æ–∑–¥–∞–µ–º backup
        backup_file = kie_models_file.with_suffix('.py.backup')
        with open(backup_file, 'w', encoding='utf-8') as f:
            f.write(content)
        logger.info(f"üíæ –°–æ–∑–¥–∞–Ω backup: {backup_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª
        with open(kie_models_file, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_models)} –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ {kie_models_file}")
        return True
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {kie_models_file}: {e}")
        return False


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    try:
        logger.info("üîç –ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ KIE API...")
        
        missing_models = await find_missing_models()
        
        if not missing_models:
            logger.info("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ API —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∫–æ–¥–µ!")
            return 0
        
        logger.info(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(missing_models)} –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π:")
        for model in missing_models:
            logger.info(f"  ‚Ä¢ {model['id']} - {model['name']} ({model['category']})")
            logger.info(f"    –¢–∏–ø: {model.get('generation_type', 'unknown')}")
            logger.info(f"    –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(model.get('input_params', {}))}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏ –≤ kie_models.py
        kie_models_file = root_dir / "kie_models.py"
        if add_models_to_kie_models_py(missing_models, kie_models_file):
            logger.info(f"\n‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ {kie_models_file}")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –º–æ–¥–µ–ª–∏ –≤ —Ñ–∞–π–ª")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–¥ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            new_code = "\n".join([format_model_for_kie_models_py(m, indent=1) for m in missing_models])
            output_file = root_dir / "NEW_MODELS_TO_ADD_MANUAL.py"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥ –≤ kie_models.py –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–æ–π ]\n\n")
                f.write(new_code)
            logger.info(f"üìù –ö–æ–¥ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
            return 1
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = {
            'total_missing': len(missing_models),
            'added_models': [
                {
                    'id': m['id'],
                    'name': m['name'],
                    'category': m['category'],
                    'generation_type': m.get('generation_type', 'unknown'),
                    'has_input_schema': bool(m.get('input_params')),
                    'input_params_count': len(m.get('input_params', {})),
                    'input_params': list(m.get('input_params', {}).keys())
                }
                for m in missing_models
            ]
        }
        
        report_file = root_dir / "MODELS_SYNC_REPORT.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_file}")
        
        return 0
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π: {e}", exc_info=True)
        return 1


if __name__ == '__main__':
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

