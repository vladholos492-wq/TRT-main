#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ KIE API –≤ kie_models.py.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∫–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å –≤ API, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∫–æ–¥–µ, –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö.
"""

import asyncio
import sys
import os
import json
from pathlib import Path
from typing import Dict, List, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
root_dir = Path(__file__).parent
sys.path.insert(0, str(root_dir))

from dotenv import load_dotenv
from kie_client import get_client
from kie_models import KIE_MODELS, get_model_by_id, normalize_model_info

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def normalize_api_model_to_kie_format(api_model: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ API –∫ —Ñ–æ—Ä–º–∞—Ç—É kie_models.py.
    """
    model_id = api_model.get('id') or api_model.get('model_id') or api_model.get('name', '')
    title = api_model.get('title') or api_model.get('name') or model_id
    description = api_model.get('description') or api_model.get('help') or api_model.get('instructions', '')
    category = api_model.get('category') or api_model.get('type') or 'Unknown'
    emoji = api_model.get('emoji') or '‚ú®'
    
    # –ü–æ–ª—É—á–∞–µ–º input_schema
    input_schema = api_model.get('input_schema') or api_model.get('input_params') or api_model.get('input') or {}
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º generation_type –Ω–∞ –æ—Å–Ω–æ–≤–µ model_id –∏ input_schema
    generation_type = api_model.get('generation_type') or api_model.get('type') or 'unknown'
    if generation_type == 'unknown':
        if 'text-to-image' in model_id.lower() or 'text_to_image' in model_id.lower():
            generation_type = 'text-to-image'
        elif 'image-to-image' in model_id.lower() or 'image_to_image' in model_id.lower():
            generation_type = 'image-to-image'
        elif 'text-to-video' in model_id.lower() or 'text_to_video' in model_id.lower():
            generation_type = 'text-to-video'
        elif 'image-to-video' in model_id.lower() or 'image_to_video' in model_id.lower():
            generation_type = 'image-to-video'
        elif 'edit' in model_id.lower():
            generation_type = 'image-edit'
        elif 'upscale' in model_id.lower():
            generation_type = 'image-upscale'
        elif 'video' in model_id.lower():
            generation_type = 'video-processing'
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º pricing (–ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
    pricing = api_model.get('pricing') or "–¶–µ–Ω–∞ —É—Ç–æ—á–Ω—è–µ—Ç—Å—è"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º help —Ç–µ–∫—Å—Ç
    help_text = description
    if not help_text:
        if 'text-to-image' in generation_type:
            help_text = "–û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –≤—ã–±–µ—Ä–∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω –∏ –ø–æ–ª—É—á–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
        elif 'image-to-image' in generation_type:
            help_text = "–û—Ç–ø—Ä–∞–≤—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        elif 'text-to-video' in generation_type:
            help_text = "–û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –∏ –ø–æ–ª—É—á–∏ –≤–∏–¥–µ–æ."
        elif 'image-to-video' in generation_type:
            help_text = "–û—Ç–ø—Ä–∞–≤—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–∏ –≤–∏–¥–µ–æ."
        else:
            help_text = f"–ò—Å–ø–æ–ª—å–∑—É–π –º–æ–¥–µ–ª—å {title} –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º example_prompt
    example_prompt = api_model.get('example_prompt') or api_model.get('example')
    if not example_prompt:
        if 'text-to-image' in generation_type or 'image-to-image' in generation_type:
            example_prompt = "–ö—Ä–∞—Å–∏–≤—ã–π –∑–∞–∫–∞—Ç –Ω–∞–¥ –æ–∫–µ–∞–Ω–æ–º —Å –ª–µ—Ç–∞—é—â–∏–º–∏ –ø—Ç–∏—Ü–∞–º–∏"
        elif 'text-to-video' in generation_type or 'image-to-video' in generation_type:
            example_prompt = "–°–ø–æ–∫–æ–π–Ω–æ–µ –≤–∏–¥–µ–æ —Å –≤–æ–ª–Ω–∞–º–∏ –Ω–∞ –ø–ª—è–∂–µ"
        else:
            example_prompt = "–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    normalized = {
        "id": model_id,
        "name": title,
        "description": description,
        "category": category,
        "emoji": emoji,
        "pricing": pricing,
        "input_params": input_schema,
        "generation_type": generation_type,
        "help": help_text,
        "example_prompt": example_prompt
    }
    
    return normalized


def format_model_for_kie_models_py(model: Dict[str, Any], indent: int = 1) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ kie_models.py.
    """
    indent_str = "    " * indent
    next_indent = "    " * (indent + 1)
    
    lines = [f"{indent_str}{{"]
    
    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
    lines.append(f'{next_indent}"id": "{model["id"]}",')
    lines.append(f'{next_indent}"name": "{model["name"]}",')
    lines.append(f'{next_indent}"description": "{model["description"]}",')
    lines.append(f'{next_indent}"category": "{model["category"]}",')
    lines.append(f'{next_indent}"emoji": "{model["emoji"]}",')
    lines.append(f'{next_indent}"pricing": "{model["pricing"]}",')
    
    # input_params
    lines.append(f'{next_indent}"input_params": {{')
    input_params = model.get("input_params", {})
    if input_params:
        for param_name, param_info in input_params.items():
            if isinstance(param_info, dict):
                lines.append(f'{next_indent}    "{param_name}": {{')
                for key, value in param_info.items():
                    if isinstance(value, str):
                        lines.append(f'{next_indent}        "{key}": "{value}",')
                    elif isinstance(value, bool):
                        lines.append(f'{next_indent}        "{key}": {str(value).lower()},')
                    elif isinstance(value, (int, float)):
                        lines.append(f'{next_indent}        "{key}": {value},')
                    elif isinstance(value, list):
                        items_str = ", ".join([f'"{item}"' if isinstance(item, str) else str(item) for item in value])
                        lines.append(f'{next_indent}        "{key}": [{items_str}],')
                    else:
                        lines.append(f'{next_indent}        "{key}": {json.dumps(value, ensure_ascii=False)},')
                lines.append(f'{next_indent}    }},')
            else:
                lines.append(f'{next_indent}    "{param_name}": {json.dumps(param_info, ensure_ascii=False)},')
    lines.append(f'{next_indent}}}')
    
    lines.append(f"{indent_str}}},")
    
    return "\n".join(lines)


async def fetch_models_from_api() -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ KIE API."""
    client = get_client()
    
    logger.info("üì° –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏–∑ KIE API...")
    models = await client.list_models()
    
    if not models:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ API. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        logger.warning("  - KIE_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        logger.warning("  - API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        logger.warning("  - –ù–µ–≤–µ—Ä–Ω—ã–π endpoint")
        return []
    
    logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –∏–∑ API")
    return models


async def find_missing_models() -> List[Dict[str, Any]]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –º–æ–¥–µ–ª–∏ –∏–∑ API, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ kie_models.py.
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ API
    api_models = await fetch_models_from_api()
    
    if not api_models:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ API. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø—É—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º.")
        return []
    
    # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–¥–∞
    code_model_ids = {model['id'] for model in KIE_MODELS}
    
    # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏
    missing_models = []
    for api_model in api_models:
        normalized = normalize_api_model_to_kie_format(api_model)
        model_id = normalized['id']
        
        if model_id and model_id not in code_model_ids:
            missing_models.append(normalized)
            logger.info(f"‚ûï –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å: {model_id} ({normalized['name']})")
    
    return missing_models


def add_models_to_kie_models_py(new_models: List[Dict[str, Any]], output_file: str = None) -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –≤ kie_models.py.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Å –∫–æ–¥–æ–º –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏.
    """
    if not new_models:
        return ""
    
    lines = []
    lines.append("\n# –ù–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –∏–∑ KIE API")
    lines.append("# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å–∫—Ä–∏–ø—Ç–æ–º add_new_models_from_api.py")
    lines.append("")
    
    for model in new_models:
        model_code = format_model_for_kie_models_py(model, indent=1)
        lines.append(model_code)
        lines.append("")
    
    return "\n".join(lines)


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    try:
        logger.info("üîç –ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ KIE API...")
        
        missing_models = await find_missing_models()
        
        if not missing_models:
            logger.info("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ API —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∫–æ–¥–µ!")
            return 0
        
        logger.info(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(missing_models)} –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π:")
        for model in missing_models:
            logger.info(f"  ‚Ä¢ {model['id']} - {model['name']} ({model['category']})")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        new_code = add_models_to_kie_models_py(missing_models)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        output_file = root_dir / "NEW_MODELS_TO_ADD.py"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(new_code)
        
        logger.info(f"\n‚úÖ –ö–æ–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
        logger.info(f"üìù –î–æ–±–∞–≤—å—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –≤ –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞ KIE_MODELS –≤ kie_models.py")
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = {
            'total_missing': len(missing_models),
            'models': [
                {
                    'id': m['id'],
                    'name': m['name'],
                    'category': m['category'],
                    'generation_type': m.get('generation_type', 'unknown'),
                    'has_input_schema': bool(m.get('input_params')),
                    'input_params_count': len(m.get('input_params', {}))
                }
                for m in missing_models
            ]
        }
        
        report_file = root_dir / "NEW_MODELS_REPORT.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_file}")
        
        return 0
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: {e}", exc_info=True)
        return 1


if __name__ == '__main__':
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

