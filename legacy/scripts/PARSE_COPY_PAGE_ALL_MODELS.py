#!/usr/bin/env python3
"""
üéØ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ô –°–ö–†–ò–ü–¢: PARSE COPY PAGE FOR EACH MODEL

–≠–¢–û –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –ò–°–¢–û–ß–ù–ò–ö –ü–†–ê–í–î–´!
–î–ª—è –ö–ê–ñ–î–û–ô –º–æ–¥–µ–ª–∏ –Ω–∞ kie.ai:
1. –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –º–æ–¥–µ–ª–∏ kie.ai/{slug}
2. –ù–∞—Ö–æ–¥–∏–º Copy page / API tab
3. –ò–∑–≤–ª–µ–∫–∞–µ–º:
   - –¢–æ—á–Ω—ã–π endpoint URL
   - –¢–æ—á–Ω—ã–π model_id (tech ID)
   - –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å —Ç–∏–ø–∞–º–∏
   - –ü—Ä–∏–º–µ—Ä—ã request/response
   - Pricing (credits/gen)
4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ SOURCE OF TRUTH

–≠–¢–û–¢ –§–ê–ô–õ –°–û–ó–î–ê–ï–¢–°–Ø –û–î–ò–ù –†–ê–ó –ò –°–¢–ê–ù–û–í–ò–¢–°–Ø –ë–ê–ó–û–ô.
–í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –ø–∞—Ä—Å–∏–Ω–≥—É –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å.
"""

import json
import httpx
import re
from pathlib import Path
from bs4 import BeautifulSoup
from datetime import datetime
from typing import Dict, List, Any, Optional


class KieCopyPageParser:
    """–ü–∞—Ä—Å–µ—Ä Copy page/API –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ Kie.ai"""
    
    def __init__(self):
        self.cache_dir = Path("cache/kie_model_pages")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.client = httpx.Client(timeout=30.0, follow_redirects=True)
        
        # –°–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        self.known_models = self._build_initial_model_list()
    
    def _build_initial_model_list(self) -> List[Dict[str, str]]:
        """–°—Ç—Ä–æ–∏–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ docs + pricing hints"""
        
        models = []
        
        # –ò–∑ docs.kie.ai –º—ã –∑–Ω–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ API
        docs_apis = [
            {"slug": "veo-3", "name": "Veo 3.1", "category": "video"},
            {"slug": "runway-gen-3-alpha", "name": "Runway Gen-3 Alpha", "category": "video"},
            {"slug": "suno-v4", "name": "Suno V4", "category": "audio"},
            {"slug": "gpt-4o-image", "name": "GPT-4o Image", "category": "image"},
            {"slug": "flux-kontext", "name": "Flux Kontext", "category": "image"},
        ]
        
        # –î–æ–±–∞–≤–∏–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ pricing hints
        additional_models = [
            {"slug": "flux-dev", "name": "Flux Dev", "category": "image"},
            {"slug": "flux-pro", "name": "Flux Pro", "category": "image"},
            {"slug": "flux-schnell", "name": "Flux Schnell", "category": "image"},
            {"slug": "stable-diffusion-3", "name": "Stable Diffusion 3", "category": "image"},
            {"slug": "kling-ai", "name": "Kling AI", "category": "video"},
            {"slug": "luma-dream-machine", "name": "Luma Dream Machine", "category": "video"},
            {"slug": "minimax-video", "name": "MiniMax Video", "category": "video"},
        ]
        
        models.extend(docs_apis)
        models.extend(additional_models)
        
        return models
    
    def fetch_model_page(self, slug: str) -> Optional[str]:
        """–°–∫–∞—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –º–æ–¥–µ–ª–∏"""
        
        cache_file = self.cache_dir / f"{slug}.html"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if cache_file.exists():
            print(f"  üì¶ Using cache: {slug}")
            return cache_file.read_text(encoding='utf-8')
        
        # –°–∫–∞—á–∏–≤–∞–µ–º
        try:
            url = f"https://kie.ai/{slug}"
            print(f"  üåê Fetching: {url}")
            response = self.client.get(url)
            
            if response.status_code == 200:
                html = response.text
                cache_file.write_text(html, encoding='utf-8')
                return html
            else:
                print(f"  ‚ùå Error {response.status_code} for {slug}")
                return None
                
        except Exception as e:
            print(f"  ‚ùå Exception fetching {slug}: {e}")
            return None
    
    def extract_copy_page_data(self, html: str, model_name: str) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Copy page/API tab
        
        –ò—â–µ–º:
        - <code> –±–ª–æ–∫–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ API
        - JSON payload –ø—Ä–∏–º–µ—Ä—ã
        - endpoint URLs
        - model_id values
        - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö —Ç–∏–ø—ã
        """
        
        soup = BeautifulSoup(html, 'lxml')
        
        data = {
            "model_name": model_name,
            "endpoints": [],
            "model_ids": [],
            "parameters": {},
            "request_examples": [],
            "response_examples": [],
            "pricing": {},
            "raw_code_blocks": []
        }
        
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ <code> –∏ <pre> –±–ª–æ–∫–∏
        code_blocks = soup.find_all(['code', 'pre'])
        for block in code_blocks:
            text = block.get_text()
            data["raw_code_blocks"].append(text)
            
            # –ò—â–µ–º endpoints
            endpoints = re.findall(r'https://api\.kie\.ai[^\s"\'<>]+', text)
            data["endpoints"].extend(endpoints)
            
            # –ò—â–µ–º model_id values
            model_ids = re.findall(r'"model":\s*"([^"]+)"', text)
            data["model_ids"].extend(model_ids)
            
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON
            try:
                if '{' in text and '}' in text:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –æ–±—ä–µ–∫—Ç
                    json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text, re.DOTALL)
                    if json_match:
                        json_obj = json.loads(json_match.group(0))
                        
                        # –ï—Å–ª–∏ —ç—Ç–æ request example
                        if 'model' in json_obj or 'prompt' in json_obj:
                            data["request_examples"].append(json_obj)
                            
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                            for key, value in json_obj.items():
                                if key not in data["parameters"]:
                                    data["parameters"][key] = {
                                        "type": type(value).__name__,
                                        "examples": []
                                    }
                                data["parameters"][key]["examples"].append(value)
                        
                        # –ï—Å–ª–∏ —ç—Ç–æ response example
                        elif 'taskId' in json_obj or 'data' in json_obj:
                            data["response_examples"].append(json_obj)
                            
            except json.JSONDecodeError:
                pass
        
        # 2. –ò—â–µ–º pricing –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        text_content = soup.get_text()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è pricing
        credits_match = re.search(r'(\d+(?:\.\d+)?)\s*credits?(?:/gen)?', text_content, re.IGNORECASE)
        usd_match = re.search(r'\$(\d+(?:\.\d+)?)(?:/gen)?', text_content)
        
        if credits_match:
            data["pricing"]["credits_per_gen"] = float(credits_match.group(1))
        if usd_match:
            data["pricing"]["usd_per_gen"] = float(usd_match.group(1))
        
        # 3. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
        data["endpoints"] = list(set(data["endpoints"]))
        data["model_ids"] = list(set(data["model_ids"]))
        
        return data
    
    def parse_all_models(self) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–º –í–°–ï –º–æ–¥–µ–ª–∏ –∏ —Å–æ–∑–¥–∞–µ–º SOURCE OF TRUTH"""
        
        print("=" * 80)
        print("üéØ PARSING COPY PAGE FOR ALL MODELS - SOURCE OF TRUTH")
        print("=" * 80)
        
        results = {
            "version": "COPY_PAGE_SOURCE_OF_TRUTH_1.0",
            "parsed_at": datetime.now().isoformat(),
            "source": "kie.ai/{slug} - Copy page/API tab",
            "models": {}
        }
        
        print(f"\nüìã Total models to parse: {len(self.known_models)}\n")
        
        for idx, model_info in enumerate(self.known_models, 1):
            slug = model_info["slug"]
            name = model_info["name"]
            category = model_info["category"]
            
            print(f"[{idx}/{len(self.known_models)}] Parsing: {name} ({slug})")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            html = self.fetch_model_page(slug)
            if not html:
                results["models"][slug] = {
                    "status": "FAILED",
                    "error": "Could not fetch page"
                }
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º Copy page –¥–∞–Ω–Ω—ã–µ
            copy_data = self.extract_copy_page_data(html, name)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            if not copy_data["endpoints"]:
                print(f"  ‚ö†Ô∏è  WARNING: No endpoints found!")
            if not copy_data["model_ids"]:
                print(f"  ‚ö†Ô∏è  WARNING: No model_ids found!")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            results["models"][slug] = {
                "status": "SUCCESS",
                "name": name,
                "category": category,
                "slug": slug,
                "copy_page_data": copy_data,
                "has_endpoint": len(copy_data["endpoints"]) > 0,
                "has_model_id": len(copy_data["model_ids"]) > 0,
                "has_pricing": len(copy_data["pricing"]) > 0
            }
            
            print(f"  ‚úÖ Endpoints: {len(copy_data['endpoints'])}")
            print(f"  ‚úÖ Model IDs: {len(copy_data['model_ids'])}")
            print(f"  ‚úÖ Parameters: {len(copy_data['parameters'])}")
            print(f"  ‚úÖ Examples: {len(copy_data['request_examples'])}")
            if copy_data["pricing"]:
                print(f"  üí∞ Pricing: {copy_data['pricing']}")
            print()
        
        # Summary
        total = len(results["models"])
        success = sum(1 for m in results["models"].values() if m["status"] == "SUCCESS")
        with_endpoint = sum(1 for m in results["models"].values() if m.get("has_endpoint"))
        with_model_id = sum(1 for m in results["models"].values() if m.get("has_model_id"))
        with_pricing = sum(1 for m in results["models"].values() if m.get("has_pricing"))
        
        results["summary"] = {
            "total_models": total,
            "successful_parses": success,
            "with_endpoint": with_endpoint,
            "with_model_id": with_model_id,
            "with_pricing": with_pricing,
            "ready_for_integration": min(with_endpoint, with_model_id)
        }
        
        print("=" * 80)
        print("üìä PARSING SUMMARY")
        print("=" * 80)
        print(f"Total models: {total}")
        print(f"Successfully parsed: {success}")
        print(f"With endpoint: {with_endpoint}")
        print(f"With model_id: {with_model_id}")
        print(f"With pricing: {with_pricing}")
        print(f"‚úÖ Ready for integration: {results['summary']['ready_for_integration']}")
        print()
        
        return results
    
    def save_results(self, results: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º SOURCE OF TRUTH"""
        
        output_file = Path("models/kie_copy_page_source_of_truth.json")
        
        with output_file.open('w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Saved SOURCE OF TRUTH: {output_file}")
        print(f"   Size: {output_file.stat().st_size / 1024:.1f} KB")
        print()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–∫–∂–µ –∫—Ä–∞—Ç–∫—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        summary_file = Path("models/kie_copy_page_summary.json")
        
        summary = {
            "version": results["version"],
            "parsed_at": results["parsed_at"],
            "summary": results["summary"],
            "models_ready": {}
        }
        
        for slug, model in results["models"].items():
            if model.get("has_endpoint") and model.get("has_model_id"):
                summary["models_ready"][slug] = {
                    "name": model["name"],
                    "category": model["category"],
                    "endpoint": model["copy_page_data"]["endpoints"][0] if model["copy_page_data"]["endpoints"] else None,
                    "model_id": model["copy_page_data"]["model_ids"][0] if model["copy_page_data"]["model_ids"] else None,
                    "pricing": model["copy_page_data"]["pricing"]
                }
        
        with summary_file.open('w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Saved summary: {summary_file}")
        print(f"   Ready models: {len(summary['models_ready'])}")


def main():
    """Main execution"""
    
    parser = KieCopyPageParser()
    results = parser.parse_all_models()
    parser.save_results(results)
    
    print("\n" + "=" * 80)
    print("üéâ SOURCE OF TRUTH CREATED!")
    print("=" * 80)
    print("\n–≠—Ç–æ—Ç —Ñ–∞–π–ª —Ç–µ–ø–µ—Ä—å –ë–ê–ó–ê –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π.")
    print("–í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –ø–∞—Ä—Å–∏–Ω–≥—É –¢–û–õ–¨–ö–û –µ—Å–ª–∏ API –∏–∑–º–µ–Ω–∏–ª—Å—è.")
    print("\n–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("1. –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Ç–µ—Å—Ç–∞–º–∏ (—Ç–æ–ø-5 –¥–µ—à–µ–≤—ã—Ö)")
    print("2. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ registry v7 –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–æ—Ç–∞")
    print()


if __name__ == "__main__":
    main()
